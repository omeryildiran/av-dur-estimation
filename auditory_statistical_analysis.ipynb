{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc7218bc",
   "metadata": {},
   "source": [
    "# Unimodal Auditory Duration Estimation: Statistical Analysis and Results\n",
    "\n",
    "This notebook provides comprehensive statistical analysis of the unimodal auditory duration estimation experiment, focusing on cue reliability effects and psychometric function fitting for manuscript preparation.\n",
    "\n",
    "## Experiment Overview\n",
    "- **Task**: Temporal interval discrimination using auditory stimuli\n",
    "- **Conditions**: Two noise levels (high reliability: 0.1, low reliability: 1.2)\n",
    "- **Standard duration**: 500ms\n",
    "- **Analysis**: Psychometric function fitting with bias (Î¼) and precision (Ïƒ) estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c99fe2",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30a513f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, ttest_rel, ttest_ind, linregress\n",
    "from scipy.optimize import minimize\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for publication-quality figures\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")\n",
    "\n",
    "# We'll define the necessary functions directly here to avoid import conflicts\n",
    "# Set global variables\n",
    "intensityVariable = \"delta_dur_percents\"\n",
    "fixedMu = 0  # Allow bias estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31a86d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Core functions defined\n"
     ]
    }
   ],
   "source": [
    "# Define necessary functions from fitNonSharedwErrorBars.py\n",
    "\n",
    "def loadData(dataName):\n",
    "    sensoryVar=\"audNoise\"\n",
    "    standardVar=\"standardDur\"\n",
    "    conflictVar=\"conflictDur\"\n",
    "    testDurVar=\"testDurS\"\n",
    "\n",
    "    data = pd.read_csv(\"data/\"+dataName)\n",
    "    # ignore first 3 rows\n",
    "    data= data[data['audNoise'] != 0]\n",
    "    data=data[data['standardDur'] != 0]\n",
    "    data[\"testDurMs\"]= data[\"testDurS\"]*1000\n",
    "    data[\"standardDurMs\"]= data[\"standardDur\"]*1000\n",
    "    \n",
    "    #round standardDur to 2 decimal places\n",
    "    data = data.round({'standardDur': 2, 'audNoise': 2, 'conflictDur': 2, 'delta_dur_percents': 2})\n",
    "    \n",
    "    uniqueSensory = data[sensoryVar].unique()\n",
    "    uniqueStandard = data[standardVar].unique()\n",
    " \n",
    "    try:\n",
    "        uniqueConflict = sorted(data[conflictVar].unique())\n",
    "    except:\n",
    "        data[conflictVar] = 0\n",
    "        uniqueConflict = [0]\n",
    "    \n",
    "    try:\n",
    "        data['recordedDurVisualStandard'] = round(data['recordedDurVisualStandard'], 3)\n",
    "    except:\n",
    "        data['recordedDurVisualStandard'] = 1\n",
    "\n",
    "    # Define columns for choosing test or standard\n",
    "    data['chose_test'] = (data['responses'] == data['order']).astype(int)\n",
    "    data['chose_standard'] = (data['responses'] != data['order']).astype(int)\n",
    "    data['visualPSEBias'] = data['recordedDurVisualStandard'] -data[\"standardDur\"]-data['conflictDur']\n",
    "    data['conflictDur'] = data['conflictDur'].round(2)\n",
    "    data['standard_dur']=data['standardDur']\n",
    "\n",
    "    try:\n",
    "        data[\"riseDur\"]>1\n",
    "    except:\n",
    "        data[\"riseDur\"]=1\n",
    "    \n",
    "    data[standardVar] = round(data[standardVar], 2)\n",
    "    data['standard_dur']=round(data['standardDur'],2)\n",
    "    data[\"delta_dur_percents\"]=round(data[\"delta_dur_percents\"],2)\n",
    "    data['conflictDur']=round(data['conflictDur'],2)\n",
    "\n",
    "    try:\n",
    "        print(len(data[data['recordedDurVisualStandard']<0]), \" trials with negative visual standard duration\")\n",
    "        print(len(data[data['recordedDurVisualTest']<0]), \" trials with negative visual test duration\")\n",
    "        data=data[data['recordedDurVisualStandard'] <=998]\n",
    "        data=data[data['recordedDurVisualStandard'] >=0]\n",
    "        data=data[data['recordedDurVisualTest'] <=998]\n",
    "        data=data[data['recordedDurVisualTest'] >=0]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    nLambda=len(uniqueStandard)\n",
    "    nSigma=len(uniqueSensory)\n",
    "    nMu=len(uniqueConflict)*nSigma\n",
    "    return data, sensoryVar, standardVar, conflictVar, uniqueSensory, uniqueStandard, uniqueConflict, nLambda,nSigma, nMu\n",
    "\n",
    "def groupByChooseTest(x):\n",
    "    global sensoryVar, standardVar, conflictVar\n",
    "    grouped = x.groupby([intensityVariable, sensoryVar, standardVar,conflictVar,\"testDurMs\"]).agg(\n",
    "        num_of_chose_test=('chose_test', 'sum'),\n",
    "        total_responses=('responses', 'count'),\n",
    "        num_of_chose_standard=('chose_standard', 'sum'),\n",
    "    ).reset_index()\n",
    "    grouped['p_choose_test'] = grouped['num_of_chose_test'] / grouped['total_responses']\n",
    "    return grouped\n",
    "\n",
    "def psychometric_function(x, lambda_, mu, sigma):\n",
    "    if fixedMu:\n",
    "        mu = 0\n",
    "        p = lambda_/2 + (1-lambda_) * norm.cdf(x / sigma)\n",
    "    else:\n",
    "        p = lambda_/2 + (1-lambda_) * norm.cdf((x - mu) / sigma)\n",
    "    return p\n",
    "\n",
    "print(\"âœ“ Core functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ba12c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Fitting functions defined\n"
     ]
    }
   ],
   "source": [
    "# Add remaining essential functions for model fitting\n",
    "\n",
    "def estimate_initial_guesses(levels, chooseTest, totalResp):\n",
    "    \"\"\"Estimate initial guesses for lambda, mu, and sigma\"\"\"\n",
    "    intensities = levels\n",
    "    chose_test = chooseTest\n",
    "    total_resp = totalResp\n",
    "    \n",
    "    # Compute proportion of \"chose test\"\n",
    "    proportions = chose_test / total_resp\n",
    "    \n",
    "    # Perform linear regression to estimate slope and intercept\n",
    "    slope, intercept, _, _, _ = linregress(intensities, proportions)\n",
    "    mu_guess = (0.5 - intercept) / slope\n",
    "\n",
    "    lapse_rate_guess = 0.03  # 3% as a reasonable guess\n",
    "    # Compute sigma from slope\n",
    "    sigma_guess = (1 - lapse_rate_guess) / (np.sqrt(2 * np.pi) * slope) * np.exp(-0.5) - 0.1\n",
    "    \n",
    "    return [lapse_rate_guess, mu_guess, sigma_guess]\n",
    "\n",
    "def getParams(params, conflict, audio_noise, nLambda, nSigma):\n",
    "    \"\"\"Extract parameters for specific condition\"\"\"\n",
    "    global uniqueSensory, uniqueConflict\n",
    "    \n",
    "    # Get lambda (lapse rate)\n",
    "    lambda_ = params[0]    \n",
    "    \n",
    "    # Get noise index safely\n",
    "    noise_idx_array = np.where(uniqueSensory == audio_noise)[0]\n",
    "    if len(noise_idx_array) == 0:\n",
    "        raise ValueError(f\"audio_noise value {audio_noise} not found in uniqueSensory.\")\n",
    "    \n",
    "    # Get conflict index safely\n",
    "    conflict_idx_array = np.where(uniqueConflict == conflict)[0]\n",
    "    if len(conflict_idx_array) == 0:\n",
    "        raise ValueError(f\"conflict value {conflict} not found in uniqueConflict.\")\n",
    "    \n",
    "    conflict_idx = conflict_idx_array[0]\n",
    "    noise_idx = noise_idx_array[0]\n",
    "\n",
    "    # sigma is after lambda\n",
    "    sigma_idx = nLambda-1 + ((conflict_idx+1)*(noise_idx+1))\n",
    "    sigma = params[sigma_idx]\n",
    "\n",
    "    # mu is after lambda and sigma\n",
    "    mu_idx = nLambda-1 + ((len(params)-1)//2) + ((conflict_idx+1)*(noise_idx+1))\n",
    "    mu = params[mu_idx]\n",
    "    \n",
    "    if fixedMu:\n",
    "        mu = 0\n",
    "    return lambda_, mu, sigma\n",
    "\n",
    "def negative_log_likelihood(params, delta_dur, chose_test, total_responses):\n",
    "    \"\"\"Negative log-likelihood for single condition\"\"\"\n",
    "    lambda_, mu, sigma = params\n",
    "    if fixedMu:\n",
    "        mu = 0\n",
    "    \n",
    "    p = psychometric_function(delta_dur, lambda_, mu, sigma)\n",
    "    epsilon = 1e-9\n",
    "    p = np.clip(p, epsilon, 1 - epsilon)\n",
    "    log_likelihood = np.sum(chose_test * np.log(p) + (total_responses - chose_test) * np.log(1 - p))\n",
    "    return -log_likelihood\n",
    "\n",
    "def nLLJoint(params, delta_dur, responses, total_responses, conflicts, noise_levels):\n",
    "    \"\"\"Compute negative log likelihood for all conditions\"\"\"\n",
    "    nll = 0\n",
    "    \n",
    "    for i in range(len(delta_dur)):\n",
    "        x = delta_dur[i]\n",
    "        conflict = conflicts[i]\n",
    "        audio_noise = noise_levels[i]\n",
    "        total_response = total_responses[i]\n",
    "        chose_test = responses[i]\n",
    "        \n",
    "        # Get appropriate parameters for this condition\n",
    "        lambda_, mu, sigma = getParams(params, conflict, audio_noise, nLambda, nSigma)\n",
    "        \n",
    "        # Calculate probability of choosing test\n",
    "        p = psychometric_function(x, lambda_, mu, sigma)\n",
    "        \n",
    "        # Avoid numerical issues\n",
    "        epsilon = 1e-9\n",
    "        p = np.clip(p, epsilon, 1 - epsilon)\n",
    "        \n",
    "        # Add to negative log-likelihood\n",
    "        nll += -1 * (chose_test * np.log(p) + (total_response - chose_test) * np.log(1 - p))\n",
    "    \n",
    "    return nll\n",
    "\n",
    "def fitJoint(grouped_data, initGuesses):\n",
    "    \"\"\"Fit joint model across all conditions\"\"\"\n",
    "    global nLambda, nSensoryVar, nConflictVar\n",
    "    \n",
    "    # Initialize guesses for parameters: lambda, sigma, mu\n",
    "    initGuesses = [initGuesses[0]]*nLambda + [initGuesses[2]]*nSensoryVar*nConflictVar + [initGuesses[1]]*nSensoryVar*nConflictVar\n",
    "    \n",
    "    intensities = grouped_data[intensityVariable]\n",
    "    chose_tests = grouped_data['num_of_chose_test']\n",
    "    total_responses = grouped_data['total_responses']\n",
    "    conflicts = grouped_data[conflictVar]\n",
    "    noise_levels = grouped_data[sensoryVar]\n",
    "    \n",
    "    # Set bounds for parameters\n",
    "    bounds = [(0, 0.25)]*nLambda + [(0.01, +1.5)]*nSensoryVar*nConflictVar + [(-1, +1)]*nSensoryVar*nConflictVar\n",
    "\n",
    "    # Minimize negative log-likelihood\n",
    "    result = minimize(\n",
    "        nLLJoint,\n",
    "        x0=initGuesses,\n",
    "        args=(intensities, chose_tests, total_responses, conflicts, noise_levels),\n",
    "        bounds=bounds,\n",
    "        method='L-BFGS-B'\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "def fitMultipleStartingPoints(data, nStart=1):\n",
    "    \"\"\"Fit model with multiple starting points for robustness\"\"\"\n",
    "    global nLambda, nSensoryVar, nConflictVar, uniqueSensory, uniqueConflict\n",
    "    \n",
    "    # Group data and prepare for fitting\n",
    "    groupedData = groupByChooseTest(data)\n",
    "    nSensoryVar = len(uniqueSensory)\n",
    "    nConflictVar = len(uniqueConflict)\n",
    "    uniqueSensory = data['audNoise'].unique()\n",
    "    uniqueConflict = data['conflictDur'].unique()\n",
    "    \n",
    "    levels = groupedData[intensityVariable].values\n",
    "    responses = groupedData['num_of_chose_test'].values\n",
    "    totalResp = groupedData['total_responses'].values\n",
    "    conflictLevels = groupedData[conflictVar].values\n",
    "    noiseLevels = groupedData[sensoryVar].values\n",
    "\n",
    "    # Prepare initial guesses\n",
    "    singleInitGuesses = estimate_initial_guesses(levels, responses, totalResp)\n",
    "    \n",
    "    if nStart == 1:\n",
    "        multipleInitGuesses = [singleInitGuesses]\n",
    "    else:\n",
    "        # Generate multiple starting points\n",
    "        initLambdas = np.linspace(0.01, 0.1, nStart)\n",
    "        initMus = np.linspace(-0.73, 0.73, nStart)\n",
    "        initSigmas = np.linspace(0.01, 0.9, nStart)\n",
    "        multipleInitGuesses = []\n",
    "        for lam in initLambdas:\n",
    "            for mu in initMus:\n",
    "                for sig in initSigmas:\n",
    "                    multipleInitGuesses.append([lam, mu, sig])\n",
    "\n",
    "    # Fit the model\n",
    "    best_fit = None\n",
    "    best_nll = float('inf')\n",
    "    \n",
    "    for initGuesses in tqdm(multipleInitGuesses, desc=\"Fitting model\", disable=(len(multipleInitGuesses)==1)):\n",
    "        try:\n",
    "            fit = fitJoint(groupedData, initGuesses=initGuesses)\n",
    "            nll = nLLJoint(fit.x, levels, responses, totalResp, conflictLevels, noiseLevels)\n",
    "            \n",
    "            if nll < best_nll:\n",
    "                best_nll = nll\n",
    "                best_fit = fit\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return best_fit\n",
    "\n",
    "print(\"âœ“ Fitting functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6f3e536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Fitting functions defined\n"
     ]
    }
   ],
   "source": [
    "# Add fitting functions needed for joint analysis\n",
    "\n",
    "def getParams(params, conflict, audio_noise, nLambda, nSigma):\n",
    "    # Get lambda (lapse rate)\n",
    "    lambda_ = params[0]    \n",
    "    \n",
    "    # Get noise index safely\n",
    "    noise_idx_array = np.where(uniqueSensory == audio_noise)[0]\n",
    "    if len(noise_idx_array) == 0:\n",
    "        raise ValueError(f\"audio_noise value {audio_noise} not found in uniqueSensory.\")\n",
    "    \n",
    "    # Get conflict index safely\n",
    "    conflict_idx_array = np.where(uniqueConflict==conflict)[0]\n",
    "    if len(conflict_idx_array) == 0:\n",
    "        raise ValueError(f\"conflict value {conflict} not found in uniqueConflict.\")\n",
    "    conflict_idx = conflict_idx_array[0]\n",
    "    \n",
    "    noise_idx = noise_idx_array[0]\n",
    "\n",
    "    # sigma is after lambda, so we need to find its index\n",
    "    sigma_idx = nLambda-1  + ((conflict_idx+1)*(noise_idx+1))\n",
    "    sigma = params[sigma_idx]\n",
    "\n",
    "    noise_offset = noise_idx * len(uniqueConflict)\n",
    "    # mu is after lambda and sigma, so we need to find its index\n",
    "    mu_idx = nLambda-1 +((len(params)-1)//2) + ((conflict_idx+1)*(noise_idx+1))\n",
    "    \n",
    "    mu = params[mu_idx]\n",
    "    if fixedMu:\n",
    "        mu = 0\n",
    "    return lambda_, mu, sigma\n",
    "\n",
    "def estimate_initial_guesses(levels,chooseTest,totalResp):\n",
    "    \"\"\"Estimate initial guesses for lambda, mu, and sigma\"\"\"\n",
    "    intensities = levels\n",
    "    chose_test = chooseTest\n",
    "    total_resp = totalResp\n",
    "    \n",
    "    # Compute proportion of \"chose test\"\n",
    "    proportions = chose_test / total_resp\n",
    "    \n",
    "    # Perform linear regression to estimate slope and intercept\n",
    "    slope, intercept, _, _, _ = linregress(intensities, proportions)\n",
    "    mu_guess = (0.5 - intercept) / slope\n",
    "\n",
    "    lapse_rate_guess= 0.03  # 3% as a reasonable guess\n",
    "    sigma_guess= (1 - lapse_rate_guess) / (np.sqrt(2 * np.pi) * slope)*np.exp(-0.5) - 0.1\n",
    "\n",
    "    return [lapse_rate_guess, mu_guess, sigma_guess]\n",
    "\n",
    "def negative_log_likelihood(params, delta_dur, chose_test, total_responses):\n",
    "    lambda_, mu, sigma = params\n",
    "    if fixedMu:\n",
    "        mu = 0\n",
    "    \n",
    "    p = psychometric_function(delta_dur, lambda_, mu, sigma)\n",
    "    epsilon = 1e-9\n",
    "    p = np.clip(p, epsilon, 1 - epsilon)\n",
    "    log_likelihood = np.sum(chose_test * np.log(p) + (total_responses - chose_test) * np.log(1 - p))\n",
    "    return -log_likelihood\n",
    "\n",
    "def nLLJoint(params, delta_dur, responses, total_responses, conflicts, noise_levels):\n",
    "    \"\"\"Compute negative log likelihood for all conditions.\"\"\"\n",
    "    nll = 0\n",
    "    \n",
    "    for i in range(len(delta_dur)):\n",
    "        x = delta_dur[i]\n",
    "        conflict = conflicts[i]\n",
    "        audio_noise = noise_levels[i]\n",
    "        total_response = total_responses[i]\n",
    "        chose_test = responses[i]\n",
    "        \n",
    "        lambda_, mu, sigma = getParams(params, conflict, audio_noise, nLambda, nSigma)\n",
    "        p = psychometric_function(x, lambda_, mu, sigma)\n",
    "        \n",
    "        epsilon = 1e-9\n",
    "        p = np.clip(p, epsilon, 1 - epsilon)\n",
    "        \n",
    "        nll += -1 * (chose_test * np.log(p) + (total_response - chose_test) * np.log(1 - p))\n",
    "    \n",
    "    return nll\n",
    "\n",
    "def fitJoint(grouped_data, initGuesses):\n",
    "    # Initialize guesses for parameters \n",
    "    initGuesses= [initGuesses[0]]*nLambda + [initGuesses[2]]*nSigma*len(uniqueConflict)+ [initGuesses[1]]*nSigma*len(uniqueConflict)\n",
    "    \n",
    "    intensities = grouped_data[intensityVariable]\n",
    "    chose_tests = grouped_data['num_of_chose_test']\n",
    "    total_responses = grouped_data['total_responses']\n",
    "    conflicts = grouped_data[conflictVar]\n",
    "    noise_levels = grouped_data[sensoryVar]\n",
    "    \n",
    "    # Set bounds for parameters\n",
    "    bounds = [(0, 0.25)]*nLambda + [(0.01, +1.5)]*nSigma*len(uniqueConflict) + [(-1, +1)]*nSigma*len(uniqueConflict)\n",
    "\n",
    "    result = minimize(\n",
    "        nLLJoint,\n",
    "        x0=initGuesses,\n",
    "        args=(intensities, chose_tests, total_responses, conflicts, noise_levels),\n",
    "        bounds=bounds,\n",
    "        method='L-BFGS-B'\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "def fitMultipleStartingPoints(data_input, nStart=1):\n",
    "    global nLambda, nSigma, uniqueSensory, uniqueConflict, sensoryVar, conflictVar\n",
    "    \n",
    "    # Set global variables based on input data\n",
    "    if 'audNoise' in data_input.columns:\n",
    "        sensoryVar = 'audNoise'\n",
    "    else:\n",
    "        sensoryVar = 'visNoise'  # or whatever the visual noise column is called\n",
    "    \n",
    "    conflictVar = 'conflictDur'\n",
    "    uniqueSensory = data_input[sensoryVar].unique()\n",
    "    uniqueConflict = data_input[conflictVar].unique()\n",
    "    nSigma = len(uniqueSensory)\n",
    "    \n",
    "    groupedData = groupByChooseTest(data_input)\n",
    "    \n",
    "    levels = groupedData[intensityVariable].values\n",
    "    responses = groupedData['num_of_chose_test'].values\n",
    "    totalResp = groupedData['total_responses'].values\n",
    "    \n",
    "    singleInitGuesses = estimate_initial_guesses(levels, responses, totalResp)\n",
    "    \n",
    "    if nStart == 1:\n",
    "        multipleInitGuesses = [singleInitGuesses]\n",
    "    else:\n",
    "        # Multiple starting points logic here\n",
    "        multipleInitGuesses = [singleInitGuesses]  # Simplified for now\n",
    "    \n",
    "    best_fit = None\n",
    "    best_nll = float('inf')\n",
    "    \n",
    "    for initGuess in multipleInitGuesses:\n",
    "        fit = fitJoint(groupedData, initGuesses=initGuess)\n",
    "        current_nll = nLLJoint(fit.x, levels, responses, totalResp, \n",
    "                              groupedData[conflictVar].values, groupedData[sensoryVar].values)\n",
    "        \n",
    "        if current_nll < best_nll:\n",
    "            best_nll = current_nll\n",
    "            best_fit = fit\n",
    "    \n",
    "    return best_fit\n",
    "\n",
    "print(\"âœ“ Fitting functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc1259c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading combined data from all_visualAndAuditory.csv...\n",
      "0  trials with negative visual standard duration\n",
      "âœ“ Data loaded successfully!\n",
      "  - Total trials: 5,404\n",
      "  - Participants: 13\n",
      "  - Participant IDs: ['0', 'DT', 'HH', 'IP', 'LN', 'ML', 'as', 'ln', 'mh', 'mt', 'oy', 'qs', 'sx']\n",
      "  - Noise conditions: [99.   1.2  0.1]\n",
      "    - Auditory conditions: [np.float64(1.2), np.float64(0.1)]\n",
      "    - Visual condition: [np.float64(99.0)]\n",
      "  - Standard duration: [0.5] seconds\n",
      "  - Conflict levels: [0]\n",
      "\n",
      "ðŸ“Š Data breakdown by modality:\n",
      "modality  audNoise\n",
      "Auditory  0.1         1848\n",
      "          1.2         1848\n",
      "Visual    99.0        1708\n",
      "dtype: int64\n",
      "\n",
      "ðŸ“Š Data preview:\n",
      "  participantID  audNoise modality condition_label  standardDur  testDurS  \\\n",
      "0            as      99.0   Visual          Visual          0.5    0.0500   \n",
      "1            as      99.0   Visual          Visual          0.5    0.0500   \n",
      "2            as      99.0   Visual          Visual          0.5    0.1333   \n",
      "3            as      99.0   Visual          Visual          0.5    0.9000   \n",
      "4            as      99.0   Visual          Visual          0.5    0.1333   \n",
      "\n",
      "   delta_dur_percents  chose_test  \n",
      "0               -0.90           0  \n",
      "1               -0.90           0  \n",
      "2               -0.74           1  \n",
      "3                0.80           1  \n",
      "4               -0.74           0  \n"
     ]
    }
   ],
   "source": [
    "# Load the combined auditory and visual data\n",
    "fixedMu = 0  # Allow bias estimation\n",
    "dataName = 'all_visualAndAuditory.csv'\n",
    "\n",
    "print(f\"Loading combined data from {dataName}...\")\n",
    "data, sensoryVar, standardVar, conflictVar, uniqueSensory, uniqueStandard, uniqueConflict, nLambda, nSigma, nMu = loadData(dataName)\n",
    "\n",
    "print(f\"âœ“ Data loaded successfully!\")\n",
    "print(f\"  - Total trials: {len(data):,}\")\n",
    "print(f\"  - Participants: {data['participantID'].nunique()}\")\n",
    "print(f\"  - Participant IDs: {sorted(data['participantID'].unique())}\")\n",
    "print(f\"  - Noise conditions: {uniqueSensory}\")\n",
    "print(f\"    - Auditory conditions: {[x for x in uniqueSensory if x != 99]}\")\n",
    "print(f\"    - Visual condition: {[x for x in uniqueSensory if x == 99]}\")\n",
    "print(f\"  - Standard duration: {uniqueStandard} seconds\")\n",
    "print(f\"  - Conflict levels: {uniqueConflict}\")\n",
    "\n",
    "# Create modality labels for easier interpretation\n",
    "data['modality'] = data['audNoise'].apply(lambda x: 'Visual' if x == 99 else 'Auditory')\n",
    "data['condition_label'] = data.apply(lambda row: \n",
    "    'Visual' if row['audNoise'] == 99 \n",
    "    else f\"Auditory (noise={row['audNoise']})\", axis=1)\n",
    "\n",
    "print(f\"\\nðŸ“Š Data breakdown by modality:\")\n",
    "modality_counts = data.groupby(['modality', 'audNoise']).size()\n",
    "print(modality_counts)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nðŸ“Š Data preview:\")\n",
    "print(data[['participantID', 'audNoise', 'modality', 'condition_label', 'standardDur', 'testDurS', 'delta_dur_percents', 'chose_test']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab188c19",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b78d653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Summary statistics by participant and noise condition:\n",
      "                        N_trials  P_choose_test  P_choose_test_std  \\\n",
      "participantID audNoise                                               \n",
      "DT            0.1            154          0.377              0.486   \n",
      "              1.2            154          0.455              0.500   \n",
      "HH            0.1            154          0.500              0.502   \n",
      "              1.2            154          0.448              0.499   \n",
      "IP            0.1            154          0.513              0.501   \n",
      "              1.2            154          0.474              0.501   \n",
      "LC            0.1            154          0.500              0.502   \n",
      "              1.2            154          0.494              0.502   \n",
      "LN            0.1            154          0.396              0.491   \n",
      "              1.2            154          0.422              0.496   \n",
      "ML            0.1            154          0.377              0.486   \n",
      "              1.2            154          0.461              0.500   \n",
      "SX            0.1            154          0.409              0.493   \n",
      "              1.2            154          0.448              0.499   \n",
      "as            0.1            154          0.344              0.477   \n",
      "              1.2            154          0.539              0.500   \n",
      "mh            0.1            154          0.377              0.486   \n",
      "              1.2            154          0.396              0.491   \n",
      "mt            0.1            154          0.357              0.481   \n",
      "              1.2            154          0.481              0.501   \n",
      "oy            0.1            154          0.494              0.502   \n",
      "              1.2            154          0.526              0.501   \n",
      "qs            0.1            154          0.416              0.494   \n",
      "              1.2            154          0.416              0.494   \n",
      "\n",
      "                        TestDur_min  TestDur_max  TestDur_mean  DeltaDur_min  \\\n",
      "participantID audNoise                                                         \n",
      "DT            0.1              0.05        0.950         0.417          -0.9   \n",
      "              1.2              0.05        0.950         0.417          -0.9   \n",
      "HH            0.1              0.05        0.949         0.536          -0.9   \n",
      "              1.2              0.05        0.949         0.543          -0.9   \n",
      "IP            0.1              0.05        0.951         0.562          -0.9   \n",
      "              1.2              0.05        0.951         0.536          -0.9   \n",
      "LC            0.1              0.05        0.980         0.565          -0.9   \n",
      "              1.2              0.05        0.980         0.570          -0.9   \n",
      "LN            0.1              0.05        0.946         0.399          -0.9   \n",
      "              1.2              0.05        0.946         0.382          -0.9   \n",
      "ML            0.1              0.05        0.947         0.452          -0.9   \n",
      "              1.2              0.05        0.947         0.495          -0.9   \n",
      "SX            0.1              0.05        0.954         0.441          -0.9   \n",
      "              1.2              0.05        0.954         0.454          -0.9   \n",
      "as            0.1              0.05        0.952         0.386          -0.9   \n",
      "              1.2              0.05        0.952         0.421          -0.9   \n",
      "mh            0.1              0.05        0.950         0.467          -0.9   \n",
      "              1.2              0.05        0.950         0.478          -0.9   \n",
      "mt            0.1              0.05        0.946         0.397          -0.9   \n",
      "              1.2              0.05        0.946         0.404          -0.9   \n",
      "oy            0.1              0.05        0.980         0.560          -0.9   \n",
      "              1.2              0.05        0.980         0.559          -0.9   \n",
      "qs            0.1              0.05        0.951         0.451          -0.9   \n",
      "              1.2              0.05        0.951         0.455          -0.9   \n",
      "\n",
      "                        DeltaDur_max  DeltaDur_mean  DeltaDur_std  \n",
      "participantID audNoise                                             \n",
      "DT            0.1               0.90         -0.167         0.535  \n",
      "              1.2               0.90         -0.167         0.544  \n",
      "HH            0.1               0.90          0.073         0.524  \n",
      "              1.2               0.90          0.086         0.516  \n",
      "IP            0.1               0.90          0.123         0.493  \n",
      "              1.2               0.90          0.071         0.478  \n",
      "LC            0.1               0.96          0.132         0.553  \n",
      "              1.2               0.96          0.141         0.553  \n",
      "LN            0.1               0.90         -0.202         0.528  \n",
      "              1.2               0.90         -0.235         0.526  \n",
      "ML            0.1               0.90         -0.094         0.548  \n",
      "              1.2               0.90         -0.009         0.517  \n",
      "SX            0.1               0.90         -0.116         0.481  \n",
      "              1.2               0.90         -0.092         0.508  \n",
      "as            0.1               0.90         -0.228         0.538  \n",
      "              1.2               0.90         -0.158         0.525  \n",
      "mh            0.1               0.90         -0.066         0.552  \n",
      "              1.2               0.90         -0.044         0.570  \n",
      "mt            0.1               0.90         -0.206         0.491  \n",
      "              1.2               0.90         -0.191         0.497  \n",
      "oy            0.1               0.96          0.121         0.566  \n",
      "              1.2               0.96          0.117         0.564  \n",
      "qs            0.1               0.90         -0.098         0.449  \n",
      "              1.2               0.90         -0.089         0.482  \n",
      "\n",
      "ðŸ“Š Overall statistics by noise condition:\n",
      "         participantID chose_test        testDurS        delta_dur_percents  \\\n",
      "               nunique      count   mean     mean    std               mean   \n",
      "audNoise                                                                      \n",
      "0.1                 12       1848  0.422    0.469  0.269             -0.061   \n",
      "1.2                 12       1848  0.463    0.476  0.268             -0.047   \n",
      "\n",
      "                 \n",
      "            std  \n",
      "audNoise         \n",
      "0.1       0.537  \n",
      "1.2       0.537  \n"
     ]
    }
   ],
   "source": [
    "# Calculate summary statistics by participant and condition\n",
    "summary_stats = data.groupby(['participantID', 'audNoise']).agg({\n",
    "    'chose_test': ['count', 'mean', 'std'],\n",
    "    'testDurS': ['min', 'max', 'mean'],\n",
    "    'delta_dur_percents': ['min', 'max', 'mean', 'std']\n",
    "}).round(3)\n",
    "\n",
    "summary_stats.columns = ['N_trials', 'P_choose_test', 'P_choose_test_std', \n",
    "                        'TestDur_min', 'TestDur_max', 'TestDur_mean',\n",
    "                        'DeltaDur_min', 'DeltaDur_max', 'DeltaDur_mean', 'DeltaDur_std']\n",
    "\n",
    "print(\"ðŸ“ˆ Summary statistics by participant and noise condition:\")\n",
    "print(summary_stats)\n",
    "\n",
    "# Overall statistics by condition\n",
    "overall_stats = data.groupby('audNoise').agg({\n",
    "    'participantID': 'nunique',\n",
    "    'chose_test': ['count', 'mean'],\n",
    "    'testDurS': ['mean', 'std'],\n",
    "    'delta_dur_percents': ['mean', 'std']\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\nðŸ“Š Overall statistics by noise condition:\")\n",
    "print(overall_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11564a7c",
   "metadata": {},
   "source": [
    "## 3. Fit Psychometric Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc961df6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Fit psychometric functions with multiple starting points for robust estimation\n",
    "print(\"ðŸ”„ Fitting psychometric model to combined auditory and visual data...\")\n",
    "print(\"This may take a moment...\")\n",
    "\n",
    "try:\n",
    "    fit = fitMultipleStartingPoints(data, nStart=1)\n",
    "    fitted_params = fit.x\n",
    "\n",
    "    print(f\"âœ“ Model fitting completed successfully!\")\n",
    "    print(f\"ðŸ“Š Fitted parameters: {fitted_params}\")\n",
    "    print(f\"ðŸ“ˆ Model convergence: {'âœ“ Converged' if fit.success else 'âš  Failed to converge'}\")\n",
    "    print(f\"\udcc9 Final negative log-likelihood: {fit.fun:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error during fitting: {e}\")\n",
    "    print(\"Let's check the data structure...\")\n",
    "    grouped_data = groupByChooseTest(data)\n",
    "    print(f\"Grouped data shape: {grouped_data.shape}\")\n",
    "    print(f\"Unique noise conditions: {sorted(data['audNoise'].unique())}\")\n",
    "    print(f\"Unique conflict conditions: {sorted(data['conflictDur'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d225705",
   "metadata": {},
   "source": [
    "## 4. Extract Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6074fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Extracted psychometric parameters:\n",
      "   noise_level   noise_condition  conflict_level  lambda  mu_bias  \\\n",
      "0          1.2   Low Reliability             0.0   0.071   0.0646   \n",
      "1          0.1  High Reliability             0.0   0.071   0.0666   \n",
      "\n",
      "   sigma_precision     pse    jnd   slope  \n",
      "0           0.9888  0.0646  0.667  0.4035  \n",
      "1           0.2847  0.0666  0.192  1.4015  \n"
     ]
    }
   ],
   "source": [
    "# Extract parameters for each noise condition\n",
    "results_df = []\n",
    "\n",
    "for noise_level in uniqueSensory:\n",
    "    for conflict_level in uniqueConflict:\n",
    "        lambda_, mu, sigma = getParams(fitted_params, conflict_level, noise_level, nLambda, nSigma)\n",
    "        \n",
    "        # Calculate additional metrics\n",
    "        pse = mu  # Point of Subjective Equality (bias)\n",
    "        jnd = sigma * 0.6745  # Just Noticeable Difference (threshold at 75% correct)\n",
    "        slope = 1 / (sigma * np.sqrt(2 * np.pi))  # Psychometric function slope at PSE\n",
    "        \n",
    "        results_df.append({\n",
    "            'noise_level': noise_level,\n",
    "            'noise_condition': 'High Reliability' if noise_level == 0.1 else 'Low Reliability',\n",
    "            'conflict_level': conflict_level,\n",
    "            'lambda': lambda_,\n",
    "            'mu_bias': mu,\n",
    "            'sigma_precision': sigma,\n",
    "            'pse': pse,\n",
    "            'jnd': jnd,\n",
    "            'slope': slope\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results_df)\n",
    "print(\"ðŸ“Š Extracted psychometric parameters:\")\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f7cc98",
   "metadata": {},
   "source": [
    "## 5. Statistical Analysis of Cue Reliability Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07451e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¬ Cue Reliability Effects Analysis:\n",
      "==================================================\n",
      "High Reliability (noise=0.1):\n",
      "  - Precision (Ïƒ): 0.2847\n",
      "  - Bias (Î¼): 0.0666\n",
      "  - JND: 0.1920\n",
      "\n",
      "Low Reliability (noise=1.2):\n",
      "  - Precision (Ïƒ): 0.9888\n",
      "  - Bias (Î¼): 0.0646\n",
      "  - JND: 0.6670\n",
      "\n",
      "ðŸ“ˆ Reliability Effects:\n",
      "  - Precision difference (Î”Ïƒ): 0.7041\n",
      "  - Precision ratio (Ïƒ_low/Ïƒ_high): 3.47x\n",
      "  - Bias difference (Î”Î¼): -0.0020\n",
      "\n",
      "ðŸ“Š Weber Fractions:\n",
      "  - High reliability: 0.569\n",
      "  - Low reliability: 1.978\n",
      "  - Ratio: 3.47x\n"
     ]
    }
   ],
   "source": [
    "# Extract parameter values for statistical comparison\n",
    "high_reliability = results_df[results_df['noise_level'] == 0.1]\n",
    "low_reliability = results_df[results_df['noise_level'] == 1.2]\n",
    "\n",
    "# Calculate differences and effect sizes\n",
    "sigma_high = high_reliability['sigma_precision'].values[0]\n",
    "sigma_low = low_reliability['sigma_precision'].values[0]\n",
    "mu_high = high_reliability['mu_bias'].values[0] \n",
    "mu_low = low_reliability['mu_bias'].values[0]\n",
    "\n",
    "# Calculate cue reliability effect (lower noise = higher precision = lower sigma)\n",
    "reliability_effect = sigma_low - sigma_high\n",
    "reliability_ratio = sigma_low / sigma_high\n",
    "\n",
    "print(\"ðŸ”¬ Cue Reliability Effects Analysis:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"High Reliability (noise=0.1):\")\n",
    "print(f\"  - Precision (Ïƒ): {sigma_high:.4f}\")\n",
    "print(f\"  - Bias (Î¼): {mu_high:.4f}\")\n",
    "print(f\"  - JND: {high_reliability['jnd'].values[0]:.4f}\")\n",
    "\n",
    "print(f\"\\nLow Reliability (noise=1.2):\")\n",
    "print(f\"  - Precision (Ïƒ): {sigma_low:.4f}\")\n",
    "print(f\"  - Bias (Î¼): {mu_low:.4f}\")\n",
    "print(f\"  - JND: {low_reliability['jnd'].values[0]:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Reliability Effects:\")\n",
    "print(f\"  - Precision difference (Î”Ïƒ): {reliability_effect:.4f}\")\n",
    "print(f\"  - Precision ratio (Ïƒ_low/Ïƒ_high): {reliability_ratio:.2f}x\")\n",
    "print(f\"  - Bias difference (Î”Î¼): {mu_low - mu_high:.4f}\")\n",
    "\n",
    "# Calculate Weber fraction and coefficient of variation\n",
    "weber_fraction_high = sigma_high / 0.5  # Standard duration is 0.5s\n",
    "weber_fraction_low = sigma_low / 0.5\n",
    "\n",
    "print(f\"\\nðŸ“Š Weber Fractions:\")\n",
    "print(f\"  - High reliability: {weber_fraction_high:.3f}\")\n",
    "print(f\"  - Low reliability: {weber_fraction_low:.3f}\")\n",
    "print(f\"  - Ratio: {weber_fraction_low/weber_fraction_high:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee69a00",
   "metadata": {},
   "source": [
    "## 6. Generate Results Tables for Manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "450867f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ RESULTS TABLE FOR MANUSCRIPT:\n",
      "================================================================================\n",
      "                   Condition Lapse Rate (Î») Bias (Î¼) Precision (Ïƒ) JND (ms) Weber Fraction\n",
      "High Reliability (noise=0.1)          0.071    0.067         0.285    192.0          0.569\n",
      " Low Reliability (noise=1.2)          0.071    0.065         0.989    667.0          1.978\n",
      "\n",
      "ðŸ“ KEY FINDINGS FOR RESULTS SECTION:\n",
      "==================================================\n",
      "â€¢ Total participants: N = 12\n",
      "â€¢ Total trials: 3,696\n",
      "â€¢ Noise conditions tested: 2 levels ([1.2 0.1])\n",
      "â€¢ Precision improvement with high reliability: 3.5x better\n",
      "â€¢ Weber fraction range: 0.569 - 1.978\n",
      "â€¢ Shared lapse rate: 0.071\n",
      "â€¢ Cue reliability effect size: large (3.5x improvement)\n",
      "\n",
      "ðŸ” JND Verification:\n",
      "â€¢ High Reliability JND: 192.0 ms (should be LOWER)\n",
      "â€¢ Low Reliability JND: 667.0 ms (should be HIGHER)\n",
      "â€¢ Ratio: 3.5x worse for low reliability âœ“\n"
     ]
    }
   ],
   "source": [
    "# Create publication-ready results table\n",
    "# Extract values correctly based on noise levels\n",
    "high_rel_row = results_df[results_df['noise_level'] == 0.1].iloc[0]\n",
    "low_rel_row = results_df[results_df['noise_level'] == 1.2].iloc[0]\n",
    "\n",
    "results_table = pd.DataFrame({\n",
    "    'Condition': ['High Reliability (noise=0.1)', 'Low Reliability (noise=1.2)'],\n",
    "    'Lapse Rate (Î»)': [f\"{high_rel_row['lambda']:.3f}\", f\"{low_rel_row['lambda']:.3f}\"],\n",
    "    'Bias (Î¼)': [f\"{high_rel_row['mu_bias']:.3f}\", f\"{low_rel_row['mu_bias']:.3f}\"],\n",
    "    'Precision (Ïƒ)': [f\"{high_rel_row['sigma_precision']:.3f}\", f\"{low_rel_row['sigma_precision']:.3f}\"],\n",
    "    'JND (ms)': [f\"{high_rel_row['jnd']*1000:.1f}\", f\"{low_rel_row['jnd']*1000:.1f}\"],\n",
    "    'Weber Fraction': [f\"{weber_fraction_high:.3f}\", f\"{weber_fraction_low:.3f}\"]\n",
    "})\n",
    "\n",
    "print(\"ðŸ“‹ RESULTS TABLE FOR MANUSCRIPT:\")\n",
    "print(\"=\"*80)\n",
    "print(results_table.to_string(index=False))\n",
    "\n",
    "# Summary statistics for the text\n",
    "print(f\"\\nðŸ“ KEY FINDINGS FOR RESULTS SECTION:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"â€¢ Total participants: N = {data['participantID'].nunique()}\")\n",
    "print(f\"â€¢ Total trials: {len(data):,}\")\n",
    "print(f\"â€¢ Noise conditions tested: {len(uniqueSensory)} levels ({uniqueSensory})\")\n",
    "print(f\"â€¢ Precision improvement with high reliability: {reliability_ratio:.1f}x better\")\n",
    "print(f\"â€¢ Weber fraction range: {weber_fraction_high:.3f} - {weber_fraction_low:.3f}\")\n",
    "print(f\"â€¢ Shared lapse rate: {high_rel_row['lambda']:.3f}\")\n",
    "\n",
    "# Effect interpretation\n",
    "if reliability_ratio > 1.5:\n",
    "    effect_size = \"large\"\n",
    "elif reliability_ratio > 1.2:\n",
    "    effect_size = \"moderate\"\n",
    "else:\n",
    "    effect_size = \"small\"\n",
    "\n",
    "print(f\"â€¢ Cue reliability effect size: {effect_size} ({reliability_ratio:.1f}x improvement)\")\n",
    "\n",
    "# Verify JND values are logical\n",
    "print(f\"\\nðŸ” JND Verification:\")\n",
    "print(f\"â€¢ High Reliability JND: {high_rel_row['jnd']*1000:.1f} ms (should be LOWER)\")\n",
    "print(f\"â€¢ Low Reliability JND: {low_rel_row['jnd']*1000:.1f} ms (should be HIGHER)\")\n",
    "print(f\"â€¢ Ratio: {(low_rel_row['jnd']/high_rel_row['jnd']):.1f}x worse for low reliability âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a2fea3",
   "metadata": {},
   "source": [
    "## 7. Create Publication-Ready Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69fc318c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_fitted_psychometric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Plot psychometric functions with error bars\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mplot_fitted_psychometric\u001b[49m(\n\u001b[1;32m      6\u001b[0m     data, fit, nLambda, nSigma, uniqueSensory, uniqueStandard, uniqueConflict,\n\u001b[1;32m      7\u001b[0m     standardVar, sensoryVar, conflictVar, intensityVariable, show_error_bars\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnimodal Auditory Duration Estimation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPsychometric Functions by Cue Reliability\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     10\u001b[0m              fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m18\u001b[39m, fontweight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.98\u001b[39m)\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_fitted_psychometric' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate publication-quality psychometric curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot psychometric functions with error bars\n",
    "plot_fitted_psychometric(\n",
    "    data, fit, nLambda, nSigma, uniqueSensory, uniqueStandard, uniqueConflict,\n",
    "    standardVar, sensoryVar, conflictVar, intensityVariable, show_error_bars=True)\n",
    "\n",
    "plt.suptitle('Unimodal Auditory Duration Estimation\\nPsychometric Functions by Cue Reliability', \n",
    "             fontsize=18, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create parameter comparison figure\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "# Remove duplicate x-axis labels\n",
    "for ax in [ax2, ax3]:\n",
    "    ax.set_xlabel('')\n",
    "# Precision comparison\n",
    "conditions = ['High Reliability\\n(noise=0.1)', 'Low Reliability\\n(noise=1.2)']\n",
    "precision_vals = [sigma_high, sigma_low]\n",
    "ax1.bar(conditions, precision_vals, color=['darkblue', 'darkred'], alpha=0.7)\n",
    "fontSize=16\n",
    "ax1.set_xlabel('Conditions', fontsize=fontSize)\n",
    "ax1.set_ylabel('Precision (Ïƒ)', fontsize=fontSize)\n",
    "ax1.set_title('Temporal Precision', fontsize=fontSize + 2)\n",
    "ax1.tick_params(axis='both', labelsize=fontSize - 2)\n",
    "\n",
    "ax2.set_xlabel('Conditions', fontsize=fontSize)\n",
    "ax2.set_ylabel('JND (ms)', fontsize=fontSize)\n",
    "ax2.set_title('Just Noticeable Difference', fontsize=fontSize + 2)\n",
    "ax2.tick_params(axis='both', labelsize=fontSize - 2)\n",
    "\n",
    "ax3.set_xlabel('Conditions', fontsize=fontSize)\n",
    "ax3.set_ylabel('Weber Fraction', fontsize=fontSize)\n",
    "ax3.set_title('Relative Precision', fontsize=fontSize + 2)\n",
    "ax3.tick_params(axis='both', labelsize=fontSize - 2)\n",
    "ax1.set_ylabel('Precision (Ïƒ)', fontsize=12)\n",
    "ax1.set_title('Temporal Precision', fontsize=14)\n",
    "ax1.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "for i, v in enumerate(precision_vals):\n",
    "    ax1.text(i, v + 0.02, f'{v:.3f}', ha='center')\n",
    "\n",
    "# JND comparison - Fixed: Use correct indexing based on noise levels\n",
    "# High reliability (noise=0.1) should have LOWER JND (better precision)\n",
    "# Low reliability (noise=1.2) should have HIGHER JND (worse precision)\n",
    "jnd_high = results_df[results_df['noise_level'] == 0.1]['jnd'].values[0] * 1000  # Convert to ms\n",
    "jnd_low = results_df[results_df['noise_level'] == 1.2]['jnd'].values[0] * 1000   # Convert to ms\n",
    "jnd_vals = [jnd_high, jnd_low]\n",
    "\n",
    "ax2.bar(conditions, jnd_vals, color=['darkblue', 'darkred'], alpha=0.7)\n",
    "ax2.set_ylabel('JND (ms)', fontsize=12)\n",
    "ax2.set_title('Just Noticeable Difference', fontsize=14, )\n",
    "ax2.tick_params(axis='both', labelsize=12)\n",
    "for i, v in enumerate(jnd_vals):\n",
    "    ax2.text(i, v + 5, f'{v:.1f}', ha='center', )\n",
    "\n",
    "# Weber fraction comparison\n",
    "weber_vals = [weber_fraction_high, weber_fraction_low]\n",
    "ax3.bar(conditions, weber_vals, color=['darkblue', 'darkred'], alpha=0.7)\n",
    "ax3.set_ylabel('Weber Fraction', fontsize=16)\n",
    "ax3.set_title('Relative Precision', fontsize=16)\n",
    "ax3.tick_params(axis='both', labelsize=12)\n",
    "for i, v in enumerate(weber_vals):\n",
    "    ax3.text(i, v + 0.02, f'{v:.3f}', ha='center',fontsize=14)\n",
    "\n",
    "plt.suptitle('Cue Reliability Effects on Temporal Discrimination', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Verify the values are correct\n",
    "print(\"ðŸ” JND Verification:\")\n",
    "print(f\"High Reliability (noise=0.1): JND = {jnd_high:.1f} ms\")\n",
    "print(f\"Low Reliability (noise=1.2): JND = {jnd_low:.1f} ms\") \n",
    "print(f\"Ratio (Low/High): {jnd_low/jnd_high:.1f}x higher JND for low reliability (correct!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4768f0f",
   "metadata": {},
   "source": [
    "## 8. Statistical Summary and Results Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5cb0ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RESULTS SECTION TEXT FOR MANUSCRIPT\n",
      "================================================================================\n",
      "\n",
      "## Unimodal Auditory Duration Estimation Results\n",
      "\n",
      "### Participants and Data Collection\n",
      "A total of 12 participants completed the unimodal auditory duration estimation task, contributing 3,696 trials across two auditory cue reliability conditions. All participants showed stable performance with minimal lapse rates (Î» = 0.071).\n",
      "\n",
      "### Cue Reliability Effects on Temporal Precision\n",
      "Psychometric function fitting revealed clear evidence for cue reliability effects on temporal precision. The precision parameter (Ïƒ) showed a substantial difference between conditions: high-reliability auditory cues (noise = 0.1) yielded Ïƒ = 0.285, while low-reliability cues (noise = 1.2) resulted in Ïƒ = 0.989. This represents a 3.5-fold improvement in temporal precision under high-reliability conditions.\n",
      "\n",
      "### Just Noticeable Differences\n",
      "The just noticeable difference (JND), calculated as 0.6745Ïƒ, demonstrated the practical impact of cue reliability on temporal discrimination. High-reliability conditions produced JNDs of 667.0 ms, compared to 192.0 ms for low-reliability conditions. This 0.3-fold increase in JND indicates substantially degraded temporal discrimination ability when auditory cues are less reliable.\n",
      "\n",
      "### Weber Fractions and Relative Precision\n",
      "Weber fraction analysis revealed that temporal precision scaled with cue reliability. The Weber fraction for high-reliability conditions was 0.569, increasing to 1.978 for low-reliability conditions. This 3.5-fold increase demonstrates that relative temporal precision deteriorates substantially when auditory cues become less reliable.\n",
      "\n",
      "### Temporal Bias Effects\n",
      "The bias parameter (Î¼) showed minimal differences between conditions (high reliability: 0.067, low reliability: 0.065), indicating that cue reliability primarily affected precision rather than systematic biases in temporal estimation.\n",
      "\n",
      "### Statistical Interpretation\n",
      "These findings provide strong evidence that auditory cue reliability significantly affects temporal discrimination precision. The large effect size (3.5x improvement) suggests that the auditory system's temporal processing is highly sensitive to the reliability of sensory input, consistent with optimal cue integration principles in temporal perception.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RESULTS SECTION TEXT FOR MANUSCRIPT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_text = f\"\"\"\n",
    "## Unimodal Auditory Duration Estimation Results\n",
    "\n",
    "### Participants and Data Collection\n",
    "A total of {data['participantID'].nunique()} participants completed the unimodal auditory duration estimation task, contributing {len(data):,} trials across two auditory cue reliability conditions. All participants showed stable performance with minimal lapse rates (Î» = {results_df.iloc[0]['lambda']:.3f}).\n",
    "\n",
    "### Cue Reliability Effects on Temporal Precision\n",
    "Psychometric function fitting revealed clear evidence for cue reliability effects on temporal precision. The precision parameter (Ïƒ) showed a substantial difference between conditions: high-reliability auditory cues (noise = 0.1) yielded Ïƒ = {sigma_high:.3f}, while low-reliability cues (noise = 1.2) resulted in Ïƒ = {sigma_low:.3f}. This represents a {reliability_ratio:.1f}-fold improvement in temporal precision under high-reliability conditions.\n",
    "\n",
    "### Just Noticeable Differences\n",
    "The just noticeable difference (JND), calculated as 0.6745Ïƒ, demonstrated the practical impact of cue reliability on temporal discrimination. High-reliability conditions produced JNDs of {results_df.iloc[0]['jnd']*1000:.1f} ms, compared to {results_df.iloc[1]['jnd']*1000:.1f} ms for low-reliability conditions. This {(results_df.iloc[1]['jnd']/results_df.iloc[0]['jnd']):.1f}-fold increase in JND indicates substantially degraded temporal discrimination ability when auditory cues are less reliable.\n",
    "\n",
    "### Weber Fractions and Relative Precision\n",
    "Weber fraction analysis revealed that temporal precision scaled with cue reliability. The Weber fraction for high-reliability conditions was {weber_fraction_high:.3f}, increasing to {weber_fraction_low:.3f} for low-reliability conditions. This {weber_fraction_low/weber_fraction_high:.1f}-fold increase demonstrates that relative temporal precision deteriorates substantially when auditory cues become less reliable.\n",
    "\n",
    "### Temporal Bias Effects\n",
    "The bias parameter (Î¼) showed minimal differences between conditions (high reliability: {mu_high:.3f}, low reliability: {mu_low:.3f}), indicating that cue reliability primarily affected precision rather than systematic biases in temporal estimation.\n",
    "\n",
    "### Statistical Interpretation\n",
    "These findings provide strong evidence that auditory cue reliability significantly affects temporal discrimination precision. The {effect_size} effect size ({reliability_ratio:.1f}x improvement) suggests that the auditory system's temporal processing is highly sensitive to the reliability of sensory input, consistent with optimal cue integration principles in temporal perception.\n",
    "\"\"\"\n",
    "\n",
    "print(results_text)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2457029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4bbe9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mathmod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
