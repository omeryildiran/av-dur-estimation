{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plot defaultrialsrialsrialss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Reset styling to default\n",
    "plt.rcdefaults()\n",
    "# Grid on\n",
    "plt.rcParams['axes.grid'] = True\n",
    "# Top and right axis spines off\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "\n",
    "# Title 18 x y labels 16 ticks 14\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "fig_w=6\n",
    "fig_h=6\n",
    "plt.rcParams['figure.figsize'] = (fig_w,fig_h )\n",
    "# Make axis equal\n",
    "#plt.rcParams['axes.axisbelow'] = True \n",
    "\n",
    "\n",
    "plt.rcParams['grid.color'] = '0.8'# Grid color\n",
    "\n",
    "# Set default color cycle\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=['#043908', '#ff7f0e', '#9467bd', '#d62728', '#364704', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "# Set default grid settings\n",
    "plt.rcParams['grid.linestyle'] = '--'\n",
    "plt.rcParams['grid.alpha'] = 0.7\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "standardDur",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "riseDur",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "order",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "preDur",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "postDur",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "isiDur",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trial_num",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "totalDur",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_dur_percents",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "deltaDurS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "testDurS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "intensities",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "current_stair",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "responses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_correct",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "response_rts",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stair_num_reversal",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "stair_is_reversal",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "response_keys",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "conflictDur",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "recordedOnsetVisualTest",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "recordedOffsetVisualTest",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "recordedDurVisualTest",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "recordedOnsetVisualStandard",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "recordedOffsetVisualStandard",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "recordedDurVisualStandard",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "modalityPostCue",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "avgAVDeltaS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "deltaDurPercentVisual",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avgAVDeltaPercent",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0add0345-3729-4bb7-8d88-bf91932008df",
       "rows": [
        [
         "0",
         "0",
         "0.4997",
         "1.1993",
         "2",
         "0.4831",
         "0.5414",
         "0.558",
         "0",
         "2.2071",
         "-0.75",
         "-0.3748",
         "0.1249",
         "5",
         "3U1D",
         "1.0",
         "True",
         "0.509",
         "0",
         "False",
         "left",
         "-0.05",
         "1.6528",
         "1.7278",
         "0.075",
         "0.4112",
         "1.0527",
         "0.6415",
         "A",
         "-0.47065",
         "-0.8830865159781762",
         "-0.8165432579890881"
        ],
        [
         "1",
         "1",
         "0.4997",
         "0.0999",
         "2",
         "0.5414",
         "0.4581",
         "0.7163",
         "1",
         "2.3154",
         "-0.8",
         "-0.3998",
         "0.0999",
         "5",
         "lapse_rate",
         "1.0",
         "True",
         "4.587",
         "0",
         "False",
         "left",
         "0.05",
         "1.8704",
         "1.9204",
         "0.05",
         "0.4703",
         "1.1118",
         "0.6415",
         "A",
         "-0.4956499999999999",
         "-0.9220576773187841",
         "-0.8610288386593921"
        ],
        [
         "2",
         "2",
         "0.4997",
         "1.1993",
         "1",
         "0.6496",
         "0.4498",
         "0.6413",
         "2",
         "3.1149",
         "0.75",
         "0.3748",
         "0.8745",
         "5",
         "3D1U",
         "1.0",
         "True",
         "1.955",
         "0",
         "False",
         "left",
         "0.0",
         "0.6087",
         "1.5748",
         "0.966",
         "2.1745",
         "2.766",
         "0.5915",
         "V",
         "0.37465",
         "0.6331360946745561",
         "0.6915680473372781"
        ],
        [
         "3",
         "3",
         "0.4997",
         "0.0999",
         "2",
         "0.4914",
         "0.5664",
         "0.5664",
         "3",
         "3.0234",
         "0.8",
         "0.3998",
         "0.8995",
         "5",
         "lapse_rate",
         "2.0",
         "True",
         "2.401",
         "0",
         "False",
         "right",
         "-0.05",
         "1.6694",
         "2.5191",
         "0.8497",
         "0.4193",
         "1.0612",
         "0.6419",
         "V",
         "0.30379999999999996",
         "0.32372643713974136",
         "0.5618632185698706"
        ],
        [
         "4",
         "4",
         "0.4997",
         "1.1993",
         "1",
         "0.5664",
         "0.5997",
         "0.683",
         "4",
         "2.4737",
         "-0.75",
         "-0.3748",
         "0.1249",
         "5",
         "2U1D",
         "2.0",
         "True",
         "1.956",
         "0",
         "False",
         "right",
         "0.05",
         "0.5227",
         "0.7395",
         "0.2168",
         "1.3564",
         "1.998",
         "0.6417",
         "A",
         "-0.39985000000000004",
         "-0.6621474209131993",
         "-0.7060737104565997"
        ],
        [
         "5",
         "5",
         "0.4997",
         "0.0999",
         "1",
         "0.4831",
         "0.5081",
         "0.8495",
         "5",
         "2.4653",
         "-0.75",
         "-0.3748",
         "0.1249",
         "5",
         "3U1D",
         "2.0",
         "True",
         "1.736",
         "0",
         "False",
         "right",
         "0.0",
         "0.44",
         "0.6564",
         "0.2164",
         "1.4648",
         "2.0564",
         "0.5916",
         "A",
         "-0.375",
         "-0.6342123056118999",
         "-0.69210615280595"
        ],
        [
         "6",
         "6",
         "0.4997",
         "0.0999",
         "2",
         "0.6247",
         "0.583",
         "0.6247",
         "6",
         "3.2066",
         "0.75",
         "0.3748",
         "0.8745",
         "5",
         "2D1U",
         "2.0",
         "True",
         "2.345",
         "0",
         "False",
         "right",
         "-0.05",
         "1.8609",
         "2.6859",
         "0.825",
         "0.5527",
         "1.1944",
         "0.6417",
         "A",
         "0.27904999999999996",
         "0.28564749883122936",
         "0.5178237494156147"
        ],
        [
         "7",
         "7",
         "0.4997",
         "0.0999",
         "2",
         "0.4747",
         "0.4747",
         "0.633",
         "7",
         "2.9566",
         "0.75",
         "0.3748",
         "0.8745",
         "5",
         "2D1U",
         "2.0",
         "True",
         "0.175",
         "0",
         "False",
         "right",
         "0.05",
         "1.7204",
         "2.5449",
         "0.8245",
         "0.4036",
         "1.0452",
         "0.6416",
         "A",
         "0.27885000000000004",
         "0.28506857855361606",
         "0.517534289276808"
        ],
        [
         "8",
         "8",
         "0.4997",
         "1.1993",
         "1",
         "0.4081",
         "0.633",
         "0.4997",
         "8",
         "2.1654",
         "-0.75",
         "-0.3748",
         "0.1249",
         "5",
         "3U1D",
         "2.0",
         "True",
         "1.853",
         "0",
         "False",
         "right",
         "0.0",
         "0.363",
         "0.5799",
         "0.2169",
         "1.038",
         "1.6298",
         "0.5918",
         "V",
         "-0.37485",
         "-0.6334910442717134",
         "-0.6917455221358567"
        ],
        [
         "9",
         "9",
         "0.4997",
         "1.1993",
         "2",
         "0.5913",
         "0.4248",
         "0.6163",
         "9",
         "2.232",
         "-0.8",
         "-0.3998",
         "0.0999",
         "5",
         "lapse_rate",
         "1.0",
         "True",
         "1.767",
         "0",
         "False",
         "left",
         "-0.05",
         "1.8197",
         "1.8696",
         "0.0499",
         "0.5197",
         "1.1615",
         "0.6418",
         "V",
         "-0.49585",
         "-0.9222499220941104",
         "-0.8611249610470553"
        ],
        [
         "10",
         "10",
         "0.4997",
         "1.1993",
         "1",
         "0.4747",
         "0.4081",
         "0.7829",
         "10",
         "2.2903",
         "-0.75",
         "-0.3748",
         "0.1249",
         "5",
         "2U1D",
         "1.0",
         "False",
         "2.416",
         "0",
         "False",
         "left",
         "0.05",
         "0.4323",
         "0.6489",
         "0.2166",
         "1.3659",
         "2.0074",
         "0.6415",
         "V",
         "-0.39985",
         "-0.6623538581449727",
         "-0.7061769290724864"
        ],
        [
         "11",
         "11",
         "0.4997",
         "1.1993",
         "2",
         "0.4997",
         "0.4414",
         "0.8829",
         "11",
         "3.1982",
         "0.75",
         "0.3748",
         "0.8745",
         "5",
         "3D1U",
         "2.0",
         "True",
         "1.503",
         "0",
         "False",
         "right",
         "0.0",
         "1.9767",
         "2.8014",
         "0.8247",
         "0.4596",
         "1.0513",
         "0.5916",
         "A",
         "0.30395",
         "0.3940162271805273",
         "0.5720081135902637"
        ],
        [
         "12",
         "12",
         "0.4997",
         "0.0999",
         "2",
         "0.4164",
         "0.4664",
         "0.5081",
         "12",
         "1.9406",
         "-0.9",
         "-0.4498",
         "0.05",
         "5",
         "2U1D",
         "1.0",
         "True",
         "2.125",
         "0",
         "False",
         "left",
         "-0.05",
         "1.5364",
         "1.5364",
         "0.0",
         "0.3449",
         "0.9868",
         "0.6419",
         "V",
         "-0.54585",
         "-1.0",
         "-0.95"
        ],
        [
         "13",
         "13",
         "0.4997",
         "0.0999",
         "1",
         "0.5913",
         "0.5081",
         "0.8412",
         "13",
         "3.3148",
         "0.75",
         "0.3748",
         "0.8745",
         "5",
         "3D1U",
         "1.0",
         "True",
         "2.322",
         "0",
         "False",
         "left",
         "0.05",
         "0.5468",
         "1.5137",
         "0.9669",
         "2.2889",
         "2.9303",
         "0.6415",
         "A",
         "0.3501",
         "0.5072486360093531",
         "0.6286243180046766"
        ],
        [
         "14",
         "14",
         "0.4997",
         "0.0999",
         "2",
         "0.5664",
         "0.4664",
         "0.533",
         "14",
         "2.2654",
         "-0.6",
         "-0.2998",
         "0.1999",
         "5",
         "3U1D",
         "1.0",
         "True",
         "4.505",
         "0",
         "False",
         "left",
         "0.0",
         "1.6891",
         "1.8392",
         "0.15",
         "0.5223",
         "1.1138",
         "0.5915",
         "A",
         "-0.37065000000000003",
         "-0.746407438715131",
         "-0.6732037193575655"
        ],
        [
         "15",
         "15",
         "0.4997",
         "1.1993",
         "2",
         "0.6163",
         "0.5414",
         "0.8829",
         "15",
         "2.6402",
         "-0.8",
         "-0.3998",
         "0.0999",
         "5",
         "lapse_rate",
         "1.0",
         "True",
         "1.782",
         "0",
         "False",
         "left",
         "-0.05",
         "2.1159",
         "2.1656",
         "0.0498",
         "0.5491",
         "1.191",
         "0.6419",
         "A",
         "-0.49595",
         "-0.9224178220906684",
         "-0.8612089110453343"
        ],
        [
         "16",
         "16",
         "0.4997",
         "1.1993",
         "1",
         "0.4747",
         "0.4498",
         "0.8745",
         "16",
         "3.0983",
         "0.6",
         "0.2998",
         "0.7996",
         "5",
         "2D1U",
         "1.0",
         "True",
         "2.807",
         "0",
         "False",
         "left",
         "0.05",
         "0.4347",
         "1.3266",
         "0.8919",
         "2.1349",
         "2.7765",
         "0.6416",
         "A",
         "0.27505",
         "0.39011845386533683",
         "0.4950592269326684"
        ],
        [
         "17",
         "17",
         "0.4997",
         "1.1993",
         "1",
         "0.4081",
         "0.633",
         "0.7829",
         "17",
         "2.5236",
         "-0.6",
         "-0.2998",
         "0.1999",
         "5",
         "3U1D",
         "2.0",
         "True",
         "1.134",
         "0",
         "False",
         "right",
         "0.0",
         "0.3627",
         "0.6543",
         "0.2916",
         "1.3965",
         "1.9877",
         "0.5912",
         "A",
         "-0.29969999999999997",
         "-0.5067658998646819",
         "-0.5533829499323409"
        ],
        [
         "18",
         "18",
         "0.4997",
         "1.1993",
         "1",
         "0.583",
         "0.4664",
         "0.8079",
         "18",
         "3.1566",
         "0.6",
         "0.2998",
         "0.7996",
         "5",
         "3D1U",
         "1.0",
         "True",
         "0.48",
         "0",
         "False",
         "left",
         "-0.05",
         "0.5404",
         "1.4317",
         "0.8913",
         "2.1732",
         "2.8146",
         "0.6414",
         "V",
         "0.27485000000000004",
         "0.3896164639850328",
         "0.4948082319925164"
        ],
        [
         "19",
         "19",
         "0.4997",
         "1.1993",
         "2",
         "0.5081",
         "0.3998",
         "0.7829",
         "19",
         "2.2904",
         "-0.8",
         "-0.3998",
         "0.0999",
         "5",
         "lapse_rate",
         "1.0",
         "True",
         "3.059",
         "0",
         "False",
         "left",
         "0.05",
         "1.9063",
         "1.9562",
         "0.05",
         "0.4399",
         "1.0815",
         "0.6416",
         "A",
         "-0.4956999999999999",
         "-0.9220698254364089",
         "-0.8610349127182044"
        ],
        [
         "20",
         "20",
         "0.4997",
         "0.0999",
         "2",
         "0.4331",
         "0.5997",
         "0.658",
         "20",
         "2.2405",
         "-0.9",
         "-0.4498",
         "0.05",
         "5",
         "2U1D",
         "1.0",
         "True",
         "2.409",
         "0",
         "False",
         "left",
         "0.0",
         "1.6838",
         "1.6838",
         "0.0",
         "0.3927",
         "0.9841",
         "0.5914",
         "A",
         "-0.5206",
         "-1.0",
         "-0.95"
        ],
        [
         "21",
         "21",
         "0.4997",
         "0.0999",
         "2",
         "0.5664",
         "0.5164",
         "0.533",
         "21",
         "2.9151",
         "0.6",
         "0.2998",
         "0.7996",
         "5",
         "2D1U",
         "2.0",
         "True",
         "2.955",
         "0",
         "False",
         "right",
         "-0.05",
         "1.7149",
         "2.4648",
         "0.75",
         "0.498",
         "1.14",
         "0.6419",
         "V",
         "0.20395",
         "0.16840629381523597",
         "0.384203146907618"
        ],
        [
         "22",
         "22",
         "0.4997",
         "0.0999",
         "1",
         "0.5997",
         "0.5081",
         "0.5664",
         "22",
         "2.2655",
         "-0.81",
         "-0.4081",
         "0.0916",
         "5",
         "2U1D",
         "2.0",
         "True",
         "1.653",
         "1",
         "True",
         "right",
         "0.05",
         "0.5561",
         "0.7392",
         "0.1831",
         "1.2394",
         "1.8812",
         "0.6417",
         "A",
         "-0.43335",
         "-0.7146641732896992",
         "-0.7623320866448496"
        ],
        [
         "23",
         "23",
         "0.4997",
         "1.1993",
         "1",
         "0.5664",
         "0.6413",
         "0.5913",
         "23",
         "2.4986",
         "-0.6",
         "-0.2998",
         "0.1999",
         "5",
         "3U1D",
         "2.0",
         "True",
         "1.343",
         "0",
         "False",
         "right",
         "0.0",
         "0.5236",
         "0.8154",
         "0.2917",
         "1.3653",
         "1.9569",
         "0.5917",
         "V",
         "-0.2999",
         "-0.507013689369613",
         "-0.5535068446848065"
        ],
        [
         "24",
         "24",
         "0.4997",
         "0.0999",
         "1",
         "0.4498",
         "0.4997",
         "0.583",
         "24",
         "2.1321",
         "-0.8",
         "-0.3998",
         "0.0999",
         "5",
         "lapse_rate",
         "2.0",
         "True",
         "0.512",
         "0",
         "False",
         "right",
         "-0.05",
         "0.4066",
         "0.598",
         "0.1914",
         "1.1145",
         "1.7564",
         "0.6418",
         "A",
         "-0.42510000000000003",
         "-0.7017762542848239",
         "-0.7508881271424119"
        ],
        [
         "25",
         "25",
         "0.4997",
         "1.1993",
         "2",
         "0.633",
         "0.5497",
         "0.5164",
         "25",
         "2.9234",
         "0.45",
         "0.2249",
         "0.7246",
         "5",
         "2D1U",
         "2.0",
         "True",
         "0.291",
         "0",
         "False",
         "right",
         "0.05",
         "1.762",
         "2.4371",
         "0.6751",
         "0.5618",
         "1.2037",
         "0.6419",
         "V",
         "0.12905",
         "0.05172145193955446",
         "0.2508607259697772"
        ],
        [
         "26",
         "26",
         "0.4997",
         "1.1993",
         "1",
         "0.6413",
         "0.4498",
         "0.7996",
         "26",
         "3.19",
         "0.6",
         "0.2998",
         "0.7996",
         "5",
         "3D1U",
         "1.0",
         "True",
         "1.678",
         "0",
         "False",
         "left",
         "0.0",
         "0.6016",
         "1.4928",
         "0.8912",
         "2.2513",
         "2.8427",
         "0.5914",
         "V",
         "0.29979999999999996",
         "0.5069327020629015",
         "0.5534663510314508"
        ],
        [
         "27",
         "27",
         "0.4997",
         "0.0999",
         "1",
         "0.5664",
         "0.4997",
         "0.5997",
         "27",
         "2.2571",
         "-0.81",
         "-0.4081",
         "0.0916",
         "5",
         "2U1D",
         "2.0",
         "True",
         "0.824",
         "1",
         "True",
         "right",
         "-0.05",
         "0.5235",
         "0.7068",
         "0.1833",
         "1.2401",
         "1.8817",
         "0.6416",
         "A",
         "-0.4332",
         "-0.7143079800498753",
         "-0.7621539900249377"
        ],
        [
         "28",
         "28",
         "0.4997",
         "0.0999",
         "1",
         "0.4248",
         "0.5164",
         "0.6746",
         "28",
         "2.8401",
         "0.45",
         "0.2249",
         "0.7246",
         "5",
         "2D1U",
         "2.0",
         "False",
         "0.934",
         "0",
         "False",
         "right",
         "0.05",
         "0.3819",
         "1.1984",
         "0.8164",
         "1.8066",
         "2.4484",
         "0.6418",
         "V",
         "0.19974999999999998",
         "0.2720473667809286",
         "0.3610236833904643"
        ],
        [
         "29",
         "29",
         "0.4997",
         "0.0999",
         "2",
         "0.4164",
         "0.5414",
         "0.5497",
         "29",
         "2.8068",
         "0.6",
         "0.2998",
         "0.7996",
         "5",
         "3D1U",
         "2.0",
         "True",
         "1.027",
         "0",
         "False",
         "right",
         "0.0",
         "1.5585",
         "2.3082",
         "0.7497",
         "0.375",
         "0.9667",
         "0.5917",
         "V",
         "0.22890000000000002",
         "0.2670272097346629",
         "0.4335136048673314"
        ],
        [
         "30",
         "30",
         "0.4997",
         "0.0999",
         "2",
         "0.5164",
         "0.583",
         "0.5081",
         "30",
         "2.2071",
         "-0.8",
         "-0.3998",
         "0.0999",
         "5",
         "lapse_rate",
         "1.0",
         "True",
         "0.32",
         "0",
         "False",
         "left",
         "-0.05",
         "1.6379",
         "1.6877",
         "0.0499",
         "0.4461",
         "1.0878",
         "0.6417",
         "A",
         "-0.4958",
         "-0.9222378058282688",
         "-0.8611189029141344"
        ],
        [
         "31",
         "31",
         "0.4997",
         "1.1993",
         "1",
         "0.5747",
         "0.4664",
         "0.5747",
         "31",
         "2.3904",
         "-0.45",
         "-0.2249",
         "0.2749",
         "5",
         "3U1D",
         "2.0",
         "True",
         "0.272",
         "0",
         "False",
         "right",
         "0.05",
         "0.5339",
         "0.9006",
         "0.3667",
         "1.4088",
         "2.0506",
         "0.6418",
         "A",
         "-0.25",
         "-0.42863820504830163",
         "-0.43931910252415085"
        ],
        [
         "32",
         "32",
         "0.4997",
         "1.1993",
         "1",
         "0.4664",
         "0.6413",
         "0.8829",
         "32",
         "2.6319",
         "-0.72",
         "-0.3581",
         "0.1416",
         "5",
         "2U1D",
         "2.0",
         "True",
         "0.659",
         "1",
         "False",
         "right",
         "0.0",
         "0.4219",
         "0.6553",
         "0.2334",
         "1.4971",
         "2.0884",
         "0.5913",
         "A",
         "-0.358",
         "-0.6052765093860984",
         "-0.6626382546930492"
        ],
        [
         "33",
         "33",
         "0.4997",
         "1.1993",
         "1",
         "0.558",
         "0.4914",
         "0.8579",
         "33",
         "2.6819",
         "-0.45",
         "-0.2249",
         "0.2749",
         "5",
         "3U1D",
         "2.0",
         "True",
         "0.575",
         "0",
         "False",
         "right",
         "-0.05",
         "0.5186",
         "0.8853",
         "0.3667",
         "1.6771",
         "2.3188",
         "0.6417",
         "A",
         "-0.24995",
         "-0.4285491662770765",
         "-0.4392745831385383"
        ],
        [
         "34",
         "34",
         "0.4997",
         "0.0999",
         "2",
         "0.5913",
         "0.533",
         "0.8995",
         "34",
         "3.2481",
         "0.45",
         "0.2249",
         "0.7246",
         "5",
         "3D1U",
         "2.0",
         "True",
         "0.436",
         "0",
         "False",
         "right",
         "0.05",
         "2.1076",
         "2.7829",
         "0.6754",
         "0.5247",
         "1.1661",
         "0.6414",
         "V",
         "0.12945",
         "0.05300904271905212",
         "0.25150452135952606"
        ],
        [
         "35",
         "35",
         "0.4997",
         "0.0999",
         "2",
         "0.5164",
         "0.5497",
         "0.5497",
         "35",
         "3.015",
         "0.8",
         "0.3998",
         "0.8995",
         "5",
         "lapse_rate",
         "2.0",
         "True",
         "0.16",
         "0",
         "False",
         "right",
         "0.0",
         "1.6606",
         "2.5103",
         "0.8497",
         "0.4769",
         "1.0689",
         "0.592",
         "A",
         "0.32875",
         "0.43530405405405415",
         "0.6176520270270272"
        ],
        [
         "36",
         "36",
         "0.4997",
         "0.0999",
         "2",
         "0.533",
         "0.558",
         "0.5414",
         "36",
         "2.8983",
         "0.54",
         "0.2665",
         "0.7662",
         "5",
         "2D1U",
         "1.0",
         "False",
         "2.117",
         "1",
         "True",
         "left",
         "-0.05",
         "1.6856",
         "2.402",
         "0.7164",
         "0.4604",
         "1.1022",
         "0.6418",
         "A",
         "0.17055",
         "0.11623558741040822",
         "0.3281177937052041"
        ],
        [
         "37",
         "37",
         "0.4997",
         "0.0999",
         "2",
         "0.4498",
         "0.6496",
         "0.7329",
         "37",
         "3.1482",
         "0.63",
         "0.3165",
         "0.8162",
         "5",
         "2D1U",
         "1.0",
         "False",
         "1.186",
         "1",
         "False",
         "left",
         "0.05",
         "1.7979",
         "2.5649",
         "0.767",
         "0.3811",
         "1.0226",
         "0.6415",
         "V",
         "0.22100000000000003",
         "0.19563522992985202",
         "0.412817614964926"
        ],
        [
         "38",
         "38",
         "0.4997",
         "1.1993",
         "2",
         "0.4081",
         "0.4747",
         "0.7496",
         "38",
         "2.407",
         "-0.45",
         "-0.2249",
         "0.2749",
         "5",
         "3U1D",
         "1.0",
         "True",
         "0.468",
         "0",
         "False",
         "left",
         "0.0",
         "1.7462",
         "1.9706",
         "0.2245",
         "0.3627",
         "0.9543",
         "0.5916",
         "V",
         "-0.296",
         "-0.6205206220419202",
         "-0.5352603110209601"
        ],
        [
         "39",
         "39",
         "0.4997",
         "1.1993",
         "2",
         "0.5164",
         "0.633",
         "0.8745",
         "39",
         "3.2482",
         "0.45",
         "0.2249",
         "0.7246",
         "5",
         "3D1U",
         "1.0",
         "False",
         "1.191",
         "0",
         "False",
         "left",
         "-0.05",
         "2.003",
         "2.6777",
         "0.6747",
         "0.4447",
         "1.086",
         "0.6414",
         "V",
         "0.1291",
         "0.05191768007483629",
         "0.25095884003741814"
        ],
        [
         "40",
         "40",
         "0.4997",
         "0.0999",
         "2",
         "0.533",
         "0.5414",
         "0.5997",
         "40",
         "2.2737",
         "-0.8",
         "-0.3998",
         "0.0999",
         "5",
         "lapse_rate",
         "1.0",
         "True",
         "0.496",
         "0",
         "False",
         "left",
         "0.05",
         "1.7499",
         "1.8",
         "0.0502",
         "0.4666",
         "1.1082",
         "0.6416",
         "V",
         "-0.49559999999999993",
         "-0.9217581047381546",
         "-0.8608790523690772"
        ],
        [
         "41",
         "41",
         "0.4997",
         "1.1993",
         "1",
         "0.4498",
         "0.608",
         "0.8745",
         "41",
         "2.5736",
         "-0.72",
         "-0.3581",
         "0.1416",
         "5",
         "2U1D",
         "1.0",
         "False",
         "2.037",
         "1",
         "False",
         "left",
         "0.0",
         "0.4047",
         "0.638",
         "0.2333",
         "1.4715",
         "2.0632",
         "0.5916",
         "A",
         "-0.35819999999999996",
         "-0.6056457065584855",
         "-0.6628228532792427"
        ],
        [
         "42",
         "42",
         "0.4997",
         "0.0999",
         "1",
         "0.4831",
         "0.4581",
         "0.6496",
         "42",
         "2.2071",
         "-0.774",
         "-0.3831",
         "0.1166",
         "5",
         "2U1D",
         "2.0",
         "True",
         "1.653",
         "2",
         "True",
         "right",
         "-0.05",
         "0.4364",
         "0.6442",
         "0.2079",
         "1.228",
         "1.8696",
         "0.6416",
         "A",
         "-0.4084",
         "-0.6759663341645885",
         "-0.7249831670822943"
        ],
        [
         "43",
         "43",
         "0.4997",
         "0.0999",
         "2",
         "0.4997",
         "0.6247",
         "0.6496",
         "43",
         "2.3736",
         "-0.8",
         "-0.3998",
         "0.0999",
         "5",
         "lapse_rate",
         "2.0",
         "False",
         "2.02",
         "0",
         "False",
         "right",
         "0.05",
         "1.7625",
         "1.8123",
         "0.0498",
         "0.429",
         "1.0705",
         "0.6415",
         "A",
         "-0.49575",
         "-0.922369446609509",
         "-0.8611847233047545"
        ],
        [
         "44",
         "44",
         "0.4997",
         "0.0999",
         "2",
         "0.558",
         "0.4997",
         "0.8079",
         "44",
         "3.2232",
         "0.72",
         "0.3581",
         "0.8579",
         "5",
         "2D1U",
         "2.0",
         "True",
         "1.954",
         "1",
         "False",
         "right",
         "0.0",
         "1.9534",
         "2.7615",
         "0.8081",
         "0.5118",
         "1.1034",
         "0.5917",
         "A",
         "0.28725",
         "0.3657258745986142",
         "0.5428629372993071"
        ],
        [
         "45",
         "45",
         "0.4997",
         "0.0999",
         "1",
         "0.4164",
         "0.5497",
         "0.7829",
         "45",
         "2.5985",
         "-0.3",
         "-0.1499",
         "0.3498",
         "5",
         "3U1D",
         "2.0",
         "True",
         "2.066",
         "0",
         "False",
         "right",
         "-0.05",
         "0.3732",
         "0.8148",
         "0.4417",
         "1.531",
         "2.1731",
         "0.6421",
         "V",
         "-0.17515000000000003",
         "-0.3121009188599907",
         "-0.3060504594299953"
        ],
        [
         "46",
         "46",
         "0.4997",
         "1.1993",
         "2",
         "0.4914",
         "0.5081",
         "0.8995",
         "46",
         "3.1649",
         "0.54",
         "0.2665",
         "0.7662",
         "5",
         "3D1U",
         "1.0",
         "False",
         "2.713",
         "1",
         "True",
         "left",
         "0.05",
         "2.0057",
         "2.7224",
         "0.7167",
         "0.4227",
         "1.0643",
         "0.6416",
         "V",
         "0.17080000000000004",
         "0.11705112219451382",
         "0.32852556109725695"
        ],
        [
         "47",
         "47",
         "0.4997",
         "1.1993",
         "2",
         "0.608",
         "0.6163",
         "0.533",
         "47",
         "3.1565",
         "0.8",
         "0.3998",
         "0.8995",
         "5",
         "lapse_rate",
         "2.0",
         "True",
         "0.231",
         "0",
         "False",
         "right",
         "0.0",
         "1.7278",
         "2.5781",
         "0.8503",
         "0.5616",
         "1.1532",
         "0.5917",
         "A",
         "0.32919999999999994",
         "0.4370458002366063",
         "0.6185229001183031"
        ],
        [
         "48",
         "48",
         "0.4997",
         "1.1993",
         "1",
         "0.3998",
         "0.5497",
         "0.7662",
         "48",
         "3.0733",
         "0.72",
         "0.3581",
         "0.8579",
         "5",
         "2D1U",
         "2.0",
         "False",
         "1.098",
         "1",
         "False",
         "right",
         "-0.05",
         "0.3526",
         "1.3026",
         "0.95",
         "2.0027",
         "2.6448",
         "0.6421",
         "A",
         "0.33299999999999996",
         "0.4795203239370814",
         "0.5997601619685407"
        ],
        [
         "49",
         "49",
         "0.4997",
         "1.1993",
         "1",
         "0.4914",
         "0.4914",
         "0.658",
         "49",
         "2.2571",
         "-0.774",
         "-0.3831",
         "0.1166",
         "5",
         "2U1D",
         "2.0",
         "True",
         "1.619",
         "2",
         "True",
         "right",
         "0.05",
         "0.4502",
         "0.6589",
         "0.2087",
         "1.2501",
         "1.8918",
         "0.6417",
         "A",
         "-0.40805",
         "-0.6747701418108151",
         "-0.7243850709054076"
        ]
       ],
       "shape": {
        "columns": 31,
        "rows": 361
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>standardDur</th>\n",
       "      <th>riseDur</th>\n",
       "      <th>order</th>\n",
       "      <th>preDur</th>\n",
       "      <th>postDur</th>\n",
       "      <th>isiDur</th>\n",
       "      <th>trial_num</th>\n",
       "      <th>totalDur</th>\n",
       "      <th>delta_dur_percents</th>\n",
       "      <th>...</th>\n",
       "      <th>recordedOnsetVisualTest</th>\n",
       "      <th>recordedOffsetVisualTest</th>\n",
       "      <th>recordedDurVisualTest</th>\n",
       "      <th>recordedOnsetVisualStandard</th>\n",
       "      <th>recordedOffsetVisualStandard</th>\n",
       "      <th>recordedDurVisualStandard</th>\n",
       "      <th>modalityPostCue</th>\n",
       "      <th>avgAVDeltaS</th>\n",
       "      <th>deltaDurPercentVisual</th>\n",
       "      <th>avgAVDeltaPercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.4997</td>\n",
       "      <td>1.1993</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4831</td>\n",
       "      <td>0.5414</td>\n",
       "      <td>0.5580</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2071</td>\n",
       "      <td>-0.750</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6528</td>\n",
       "      <td>1.7278</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.4112</td>\n",
       "      <td>1.0527</td>\n",
       "      <td>0.6415</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.47065</td>\n",
       "      <td>-0.883087</td>\n",
       "      <td>-0.816543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4997</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5414</td>\n",
       "      <td>0.4581</td>\n",
       "      <td>0.7163</td>\n",
       "      <td>1</td>\n",
       "      <td>2.3154</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8704</td>\n",
       "      <td>1.9204</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.4703</td>\n",
       "      <td>1.1118</td>\n",
       "      <td>0.6415</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.49565</td>\n",
       "      <td>-0.922058</td>\n",
       "      <td>-0.861029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.4997</td>\n",
       "      <td>1.1993</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6496</td>\n",
       "      <td>0.4498</td>\n",
       "      <td>0.6413</td>\n",
       "      <td>2</td>\n",
       "      <td>3.1149</td>\n",
       "      <td>0.750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6087</td>\n",
       "      <td>1.5748</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>2.1745</td>\n",
       "      <td>2.7660</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>V</td>\n",
       "      <td>0.37465</td>\n",
       "      <td>0.633136</td>\n",
       "      <td>0.691568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.4997</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4914</td>\n",
       "      <td>0.5664</td>\n",
       "      <td>0.5664</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0234</td>\n",
       "      <td>0.800</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6694</td>\n",
       "      <td>2.5191</td>\n",
       "      <td>0.8497</td>\n",
       "      <td>0.4193</td>\n",
       "      <td>1.0612</td>\n",
       "      <td>0.6419</td>\n",
       "      <td>V</td>\n",
       "      <td>0.30380</td>\n",
       "      <td>0.323726</td>\n",
       "      <td>0.561863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.4997</td>\n",
       "      <td>1.1993</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5664</td>\n",
       "      <td>0.5997</td>\n",
       "      <td>0.6830</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4737</td>\n",
       "      <td>-0.750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5227</td>\n",
       "      <td>0.7395</td>\n",
       "      <td>0.2168</td>\n",
       "      <td>1.3564</td>\n",
       "      <td>1.9980</td>\n",
       "      <td>0.6417</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.39985</td>\n",
       "      <td>-0.662147</td>\n",
       "      <td>-0.706074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>356</td>\n",
       "      <td>0.4997</td>\n",
       "      <td>1.1993</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6163</td>\n",
       "      <td>0.5997</td>\n",
       "      <td>0.8162</td>\n",
       "      <td>356</td>\n",
       "      <td>3.4064</td>\n",
       "      <td>0.756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5708</td>\n",
       "      <td>1.5375</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>2.3125</td>\n",
       "      <td>2.9041</td>\n",
       "      <td>0.5916</td>\n",
       "      <td>V</td>\n",
       "      <td>0.37495</td>\n",
       "      <td>0.634043</td>\n",
       "      <td>0.695022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>357</td>\n",
       "      <td>0.4997</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5997</td>\n",
       "      <td>0.5247</td>\n",
       "      <td>0.7496</td>\n",
       "      <td>357</td>\n",
       "      <td>2.6902</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9661</td>\n",
       "      <td>2.2323</td>\n",
       "      <td>0.2662</td>\n",
       "      <td>0.5326</td>\n",
       "      <td>1.1743</td>\n",
       "      <td>0.6416</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.27930</td>\n",
       "      <td>-0.585100</td>\n",
       "      <td>-0.478550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>358</td>\n",
       "      <td>0.4997</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6080</td>\n",
       "      <td>0.4414</td>\n",
       "      <td>0.6413</td>\n",
       "      <td>358</td>\n",
       "      <td>2.9900</td>\n",
       "      <td>0.594</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8655</td>\n",
       "      <td>2.6158</td>\n",
       "      <td>0.7503</td>\n",
       "      <td>0.5406</td>\n",
       "      <td>1.1825</td>\n",
       "      <td>0.6418</td>\n",
       "      <td>A</td>\n",
       "      <td>0.20415</td>\n",
       "      <td>0.169056</td>\n",
       "      <td>0.381528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>359</td>\n",
       "      <td>0.4997</td>\n",
       "      <td>1.1993</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5830</td>\n",
       "      <td>0.5330</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>359</td>\n",
       "      <td>3.3398</td>\n",
       "      <td>0.800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5388</td>\n",
       "      <td>1.5300</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>2.3133</td>\n",
       "      <td>2.9052</td>\n",
       "      <td>0.5918</td>\n",
       "      <td>V</td>\n",
       "      <td>0.39965</td>\n",
       "      <td>0.675059</td>\n",
       "      <td>0.737530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>360</td>\n",
       "      <td>0.4997</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4914</td>\n",
       "      <td>0.5330</td>\n",
       "      <td>0.6913</td>\n",
       "      <td>360</td>\n",
       "      <td>2.5985</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7937</td>\n",
       "      <td>2.1275</td>\n",
       "      <td>0.3339</td>\n",
       "      <td>0.4191</td>\n",
       "      <td>1.0605</td>\n",
       "      <td>0.6414</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.21205</td>\n",
       "      <td>-0.479420</td>\n",
       "      <td>-0.356710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  standardDur  riseDur  order  preDur  postDur  isiDur  \\\n",
       "0             0       0.4997   1.1993      2  0.4831   0.5414  0.5580   \n",
       "1             1       0.4997   0.0999      2  0.5414   0.4581  0.7163   \n",
       "2             2       0.4997   1.1993      1  0.6496   0.4498  0.6413   \n",
       "3             3       0.4997   0.0999      2  0.4914   0.5664  0.5664   \n",
       "4             4       0.4997   1.1993      1  0.5664   0.5997  0.6830   \n",
       "..          ...          ...      ...    ...     ...      ...     ...   \n",
       "356         356       0.4997   1.1993      1  0.6163   0.5997  0.8162   \n",
       "357         357       0.4997   0.0999      2  0.5997   0.5247  0.7496   \n",
       "358         358       0.4997   0.0999      2  0.6080   0.4414  0.6413   \n",
       "359         359       0.4997   1.1993      1  0.5830   0.5330  0.8246   \n",
       "360         360       0.4997   0.0999      2  0.4914   0.5330  0.6913   \n",
       "\n",
       "     trial_num  totalDur  delta_dur_percents  ...  recordedOnsetVisualTest  \\\n",
       "0            0    2.2071              -0.750  ...                   1.6528   \n",
       "1            1    2.3154              -0.800  ...                   1.8704   \n",
       "2            2    3.1149               0.750  ...                   0.6087   \n",
       "3            3    3.0234               0.800  ...                   1.6694   \n",
       "4            4    2.4737              -0.750  ...                   0.5227   \n",
       "..         ...       ...                 ...  ...                      ...   \n",
       "356        356    3.4064               0.756  ...                   0.5708   \n",
       "357        357    2.6902              -0.372  ...                   1.9661   \n",
       "358        358    2.9900               0.594  ...                   1.8655   \n",
       "359        359    3.3398               0.800  ...                   0.5388   \n",
       "360        360    2.5985              -0.234  ...                   1.7937   \n",
       "\n",
       "     recordedOffsetVisualTest  recordedDurVisualTest  \\\n",
       "0                      1.7278                 0.0750   \n",
       "1                      1.9204                 0.0500   \n",
       "2                      1.5748                 0.9660   \n",
       "3                      2.5191                 0.8497   \n",
       "4                      0.7395                 0.2168   \n",
       "..                        ...                    ...   \n",
       "356                    1.5375                 0.9667   \n",
       "357                    2.2323                 0.2662   \n",
       "358                    2.6158                 0.7503   \n",
       "359                    1.5300                 0.9913   \n",
       "360                    2.1275                 0.3339   \n",
       "\n",
       "    recordedOnsetVisualStandard  recordedOffsetVisualStandard  \\\n",
       "0                        0.4112                        1.0527   \n",
       "1                        0.4703                        1.1118   \n",
       "2                        2.1745                        2.7660   \n",
       "3                        0.4193                        1.0612   \n",
       "4                        1.3564                        1.9980   \n",
       "..                          ...                           ...   \n",
       "356                      2.3125                        2.9041   \n",
       "357                      0.5326                        1.1743   \n",
       "358                      0.5406                        1.1825   \n",
       "359                      2.3133                        2.9052   \n",
       "360                      0.4191                        1.0605   \n",
       "\n",
       "     recordedDurVisualStandard  modalityPostCue  avgAVDeltaS  \\\n",
       "0                       0.6415                A     -0.47065   \n",
       "1                       0.6415                A     -0.49565   \n",
       "2                       0.5915                V      0.37465   \n",
       "3                       0.6419                V      0.30380   \n",
       "4                       0.6417                A     -0.39985   \n",
       "..                         ...              ...          ...   \n",
       "356                     0.5916                V      0.37495   \n",
       "357                     0.6416                A     -0.27930   \n",
       "358                     0.6418                A      0.20415   \n",
       "359                     0.5918                V      0.39965   \n",
       "360                     0.6414                A     -0.21205   \n",
       "\n",
       "     deltaDurPercentVisual avgAVDeltaPercent  \n",
       "0                -0.883087         -0.816543  \n",
       "1                -0.922058         -0.861029  \n",
       "2                 0.633136          0.691568  \n",
       "3                 0.323726          0.561863  \n",
       "4                -0.662147         -0.706074  \n",
       "..                     ...               ...  \n",
       "356               0.634043          0.695022  \n",
       "357              -0.585100         -0.478550  \n",
       "358               0.169056          0.381528  \n",
       "359               0.675059          0.737530  \n",
       "360              -0.479420         -0.356710  \n",
       "\n",
       "[361 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "dataName=\"_mainExpAvDurEstimate_2025-03-27_15h13.32.171.csv\"\n",
    "#\"_visualDurEstimate_2025-03-12_20h35.26.573.csv\"\n",
    "\n",
    "data = pd.read_csv(\"dataAvMain/\"+dataName)\n",
    "data[:4]\n",
    "data['avgAVDeltaS'] = (data['deltaDurS'] + (data['recordedDurVisualTest'] - data['recordedDurVisualStandard'])) / 2\n",
    "# Calculate deltaDurPercentVisual just as the difference between the test and standard visual durations over the standard visual duration\n",
    "data['deltaDurPercentVisual'] = ((data['recordedDurVisualTest'] - data['recordedDurVisualStandard']) / data['recordedDurVisualStandard'] \n",
    ")\n",
    "\n",
    "data['avgAVDeltaPercent'] = data[['delta_dur_percents', 'deltaDurPercentVisual']].mean(axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensityVariable=\"avgAVDeltaPercent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Psychometric Function and Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def psychometric_function(intensities, lapse_rate, mu, sigma):\n",
    "    # Cumulative distribution function with mean mu and standard deviation sigma\n",
    "    cdf = norm.cdf(intensities, loc=mu, scale=sigma) \n",
    "    # take into account of lapse rate and return the probability of choosing test\n",
    "    return lapse_rate * 0.5 + (1 - lapse_rate) * cdf \n",
    "\n",
    "def derivative_psychometric_function(intensities, lapse_rate, mu, sigma):\n",
    "    #F'(x) = (1-lambda)*(1(/sqrt(2*pi)sigma)exp((x-mu)^2/sigma^2)\n",
    "\n",
    "    return (1 - lapse_rate) * (1 / (np.sqrt(2 * np.pi) * sigma)) * np.exp(-((intensities - mu) ** 2) / (2 * sigma ** 2))    \n",
    "\n",
    "# Negative log-likelihood\n",
    "def negative_log_likelihood(params, delta_dur, chose_test, total_responses):\n",
    "    \n",
    "    lambda_, mu, sigma = params # Unpack parameters\n",
    "\n",
    "    \n",
    "    p = psychometric_function(delta_dur, lambda_, mu, sigma) # Compute probability of choosing test\n",
    "    epsilon = 1e-9 # Add a small number to avoid log(0) when calculating the log-likelihood\n",
    "    p = np.clip(p, epsilon, 1 - epsilon) # Clip p to avoid log(0) and log(1)\n",
    "    # Compute the negative log-likelihood\n",
    "    log_likelihood = np.sum(chose_test * np.log(p) + (total_responses - chose_test) * np.log(1 - p))\n",
    "    return -log_likelihood\n",
    "\n",
    "\n",
    "# Fit psychometric function\n",
    "def fit_psychometric_function(levels,nResp, totalResp,init_guesses=[0,0,0]):\n",
    "    # then fits the psychometric function\n",
    "    # order is lambda mu sigma\n",
    "    #initial_guess = [0, -0.2, 0.05]  # Initial guess for [lambda, mu, sigma]\n",
    "    bounds = [(0, 0.2), (-0.4, +0.4), (0.01, 1)]  # Reasonable bounds\n",
    "    # fitting is done here\n",
    "    result = minimize(\n",
    "        negative_log_likelihood, x0=init_guesses, \n",
    "        args=(levels, nResp, totalResp),  # Pass the data and fixed parameters\n",
    "        bounds=bounds,\n",
    "        method='Nelder-Mead'\n",
    "    )\n",
    "    # returns the fitted parameters lambda, mu, sigma\n",
    "    return result.x\n",
    "\n",
    "# Total NLL unified fitting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Negative log-likelihood\n",
    "def negative_log_likelihood_seqFixing(params, delta_dur, chose_test, totalResp, fixedLapse=None,fixedSigma=None):\n",
    "    if fixedLapse== None and fixedSigma== None:\n",
    "        lambda_, mu, sigma = params # Unpack parameters\n",
    "    elif  fixedLapse is not None and fixedSigma== None:\n",
    "        lambda_ = fixedLapse\n",
    "        mu, sigma = params\n",
    "    elif fixedSigma != None and fixedLapse != None:\n",
    "        mu=params\n",
    "        sigma = fixedSigma\n",
    "        lambda_=fixedLapse\n",
    "    \n",
    "    p = psychometric_function(delta_dur, lambda_, mu, sigma) # Compute probability of choosing test\n",
    "    \n",
    "    epsilon = 1e-9 # Add a small number to avoid log(0) when calculating the log-likelihood\n",
    "    p = np.clip(p, epsilon, 1 - epsilon) # Clip p to avoid log(0) and log(1)\n",
    "    # Compute the negative log-likelihood\n",
    "    log_likelihood = np.sum(chose_test * np.log(p) + (totalResp - chose_test) * np.log(1 - p))\n",
    "    return -log_likelihood\n",
    "\n",
    "# Fit psychometric function\n",
    "def fit_psychometric_function_seqFixing(levels,nResp, totalResp,init_guesses=[0,0,0], fixedLapse=None,fixedSigma=None):\n",
    "    # then fits the psychometric function\n",
    "    # order is lambda mu sigma\n",
    "    #initial_guess = [0, -0.2, 0.05]  # Initial guess for [lambda, mu, sigma]\n",
    "    bounds = [(0, 0.2), (-0.4, +0.4), (0.01, 1)]  # Reasonable bounds\n",
    "    init_guesses=init_guesses\n",
    "    \n",
    "    # Lambda and Sigma fixed Optimize for MU\n",
    "    if fixedLapse is not None and fixedSigma is not None:\n",
    "        # If both lapse rate and sigma are fixed, we only optimize mu\n",
    "        bounds = [(-0.2, +0.2)]  # Only mu is optimized\n",
    "        init_guesses = [init_guesses[1]]  # Start with the initial guess for mu\n",
    "   \n",
    "    # Lambda is fixed, we OPTIMIZE FOR MU AND SIGMA\n",
    "    elif fixedLapse!= None and fixedSigma== None:\n",
    "        # If only lapse rate is fixed, we optimize mu and sigma\n",
    "        bounds = [ (-0.2, +0.2), (0.02, 1)]  # Lapse rate fixed, optimize mu and sigma\n",
    "        init_guesses = init_guesses[1:]  # Start with the initial guesses for mu and sigma\n",
    "    \n",
    "    #  Sigma is fixed, we OPTIMIZE LAMBDA and MU\n",
    "    elif fixedSigma!= None and fixedLapse== None: \n",
    "        # If only sigma is fixed, we optimize lambda and mu\n",
    "        bounds = [(0, 0.2), (-0.2, +0.2)]  # Lapse rate and mu are optimized\n",
    "        init_guesses = [init_guesses[0], init_guesses[1]]  # Start with the initial guesses for lambda and mu\n",
    "\n",
    "\n",
    "  #  bounds=[[0,-0.8,0.05],[0.06,0.8,1]]\n",
    "    # fitting is done here\n",
    "    result = minimize(\n",
    "        negative_log_likelihood_seqFixing, x0=init_guesses, \n",
    "        args=(levels, nResp, totalResp,fixedLapse, fixedSigma),  # Pass the data and fixed parameters\n",
    "        bounds=bounds,\n",
    "        method='Nelder-Mead'\n",
    "    )\n",
    "    # returns the fitted parameters lambda, mu, sigma\n",
    "    return result.x\n",
    "\n",
    "# Compute sigma from slope\n",
    "def compute_sigma_from_slope(slope, lapse_rate=0.02):\n",
    "    sigma = (1 - lapse_rate) / (np.sqrt(2 * np.pi) * slope)*np.exp(-0.5)\n",
    "    return sigma\n",
    "\n",
    "\n",
    "def fitMultipleStartingPoints(levels, nResp, totalResp, multipleInitGuesses, fixedLapse=None,fixedSigma=None):\n",
    "    best_fit = None\n",
    "    best_nll = float('inf')  # Initialize with infinity\n",
    "\n",
    "    for init_guesses in multipleInitGuesses:\n",
    "        try:\n",
    "            fit = fit_psychometric_function(levels, nResp, totalResp, init_guesses, fixedLapse, fixedSigma)\n",
    "            nll = negative_log_likelihood(fit, levels, nResp, totalResp,fixedLapse,fixedSigma)\n",
    "\n",
    "            if nll < best_nll:\n",
    "                best_nll = nll\n",
    "                best_fit = fit\n",
    "        except Exception as e:\n",
    "            print(f\"Error fitting with initial guesses {init_guesses}: {e}\")\n",
    "\n",
    "    return best_fit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Raw psychometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rawNegLogLike(params, level, response):\n",
    "    # Unpack parameters\n",
    "    lapse_rate, mu, sigma = params\n",
    "    # Compute the probability of choosing test\n",
    "    p = psychometric_function(level, lapse_rate, mu, sigma)\n",
    "    # Add a small number to avoid log(0)\n",
    "    epsilon = 1e-9\n",
    "    p = np.clip(p, epsilon, 1 - epsilon)\n",
    "    # Compute the negative log-likelihood\n",
    "    log_likelihood = np.sum(response * np.log(p) + (1 - response) * np.log(1 - p))\n",
    "    return -log_likelihood\n",
    "\n",
    "# Fit psychometric function\n",
    "def fitPsychometricRaw(levels, response,init_guesses=[0,0,0]):\n",
    "    #initial_guess = [0, -0.2, 0.05]  # Initial guess for [lambda, mu, sigma]\n",
    "    bounds = [(0, 0.2), (-0.4, +0.4), (0.05, 1)]  # Reasonable bounds\n",
    "  #  bounds=[[0,-0.8,0.05],[0.06,0.8,1]]\n",
    "    # fitting is done here\n",
    "    result = minimize(\n",
    "        rawNegLogLike, x0=init_guesses, \n",
    "        args=(levels, response),\n",
    "        bounds=bounds,\n",
    "        method='Nelder-Mead'\n",
    "    )\n",
    "    # returns the fitted parameters lambda, mu, sigma\n",
    "    return result.x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       True\n",
      "1      False\n",
      "2       True\n",
      "3      False\n",
      "4       True\n",
      "       ...  \n",
      "356     True\n",
      "357    False\n",
      "358    False\n",
      "359     True\n",
      "360    False\n",
      "Name: riseDur, Length: 361, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Define columns for chosing test or standard\n",
    "data['chose_test'] = (data['responses'] == data['order']).astype(int)\n",
    "data['chose_standard'] = (data['responses'] != data['order']).astype(int)\n",
    "try:\n",
    "    print(data[\"riseDur\"]>1)\n",
    "except:\n",
    "    data[\"riseDur\"]=1\n",
    "\n",
    "data['standard_dur']=data['standardDur']\n",
    "\n",
    "def groupByChooseTest(x):\n",
    "    grouped = x.groupby([intensityVariable, 'riseDur', 'standard_dur']).agg(\n",
    "        num_of_chose_test=('chose_test', 'sum'),\n",
    "        total_responses=('responses', 'count'),\n",
    "        num_of_chose_standard=('chose_standard', 'sum')\n",
    "    ).reset_index()\n",
    "    grouped['p_choose_test'] = grouped['num_of_chose_test'] / grouped['total_responses']\n",
    "\n",
    "    return grouped\n",
    "\n",
    "def groupByStandardDur(x):\n",
    "    grouped = x.groupby([intensityVariable, 'riseDur', 'standard_dur']).agg(\n",
    "        num_of_chose_test=('chose_test', 'sum'),\n",
    "        total_responses=('responses', 'count'),\n",
    "        num_of_chose_standard=('chose_standard', 'sum')\n",
    "    ).reset_index()\n",
    "    grouped['pChooseStandard'] = grouped['num_of_chose_standard'] / grouped['total_responses']\n",
    "\n",
    "    return grouped\n",
    "\n",
    "grouped=groupByChooseTest(data)\n",
    "# p_choose_test\n",
    "#sort the group\n",
    "grouped = grouped.sort_values([ 'standard_dur'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "def estimate_initial_guesses(levels,chooseTest,totalResp, max_sigma_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Estimate initial guesses for lambda, mu, and sigma with slope adjustment and sigma regularization.\n",
    "    \"\"\"\n",
    "    intensities = levels\n",
    "    chose_test = chooseTest\n",
    "    total_resp = totalResp\n",
    "    \n",
    "    # Compute proportion of \"chose test\"\n",
    "    proportions = chose_test / total_resp\n",
    "    \n",
    "    # Perform linear regression to estimate slope and intercept\n",
    "    slope, intercept, _, _, _ = linregress(intensities, proportions)\n",
    "    mu_guess = (0.5 - intercept) / slope\n",
    "\n",
    "    #print(slope, intercept)\n",
    "    lapse_rate_guess= 0.03  # 5% as a reasonable guess\n",
    "    sigma_guess= compute_sigma_from_slope(slope,lapse_rate_guess)-0.1\n",
    "\n",
    "    # Regularize sigma to avoid overestimation\n",
    "    intensity_range = np.abs(max(intensities)) - np.abs(min(intensities))\n",
    "    max_sigma = intensity_range * max_sigma_ratio\n",
    "    #sigma_guess = min(sigma_guess, max_sigma)\n",
    "    #sigma_guess=sigma_guess/3\n",
    "    \n",
    "    return [lapse_rate_guess, mu_guess, sigma_guess]\n",
    "estimate_initial_guesses(grouped[intensityVariable],grouped['num_of_chose_test'],grouped['total_responses'])\n",
    "\n",
    "\n",
    "def multipleStartsFit(levels, responses, n_starts=10, init_guesses=[0,0,0], fixedLapse=None,fixedSigma=None):\n",
    "    \"\"\"\n",
    "    Fit the psychometric function with multiple random starts to avoid local minima.\n",
    "    \"\"\"\n",
    "    best_fit = None\n",
    "    best_neg_log_likelihood = float('inf')\n",
    "\n",
    "    for _ in range(n_starts):\n",
    "        # Generate random initial guesses\n",
    "        if fixedLapse is not None and fixedSigma is not None:\n",
    "            init_guess = [init_guesses[1]]  # Only optimize mu\n",
    "        else:\n",
    "            #init_guess = np.random.uniform(low=[0, -0.4, 0.05], high=[0.2, 0.4, 1], size=3)  # Random guesses for [lambda, mu, sigma]\n",
    "            init_guess.append(np.random.uniform(0,0.2))  # Random guess for lambda\n",
    "        # Fit the psychometric function\n",
    "        try:\n",
    "            fit_params = fit_psychometric_function(levels, responses, n_starts, init_guess, fixedLapse, fixedSigma)\n",
    "            neg_log_likelihood = negative_log_likelihood(fit_params, levels, responses, len(responses), fixedLapse, fixedSigma)\n",
    "\n",
    "            # Check if this fit is better than the previous best\n",
    "            if neg_log_likelihood < best_neg_log_likelihood:\n",
    "                best_fit = fit_params\n",
    "                best_neg_log_likelihood = neg_log_likelihood\n",
    "        except Exception as e:\n",
    "            print(f\"Error during fitting: {e}\")\n",
    "            continue\n",
    "\n",
    "    return best_fit\n",
    "\n",
    "def estimateInitialGuessesRaw(levels,responses,maxSigmaRatio=0.2):\n",
    "    \"\"\"\n",
    "    Estimate initial guesses for lambda, mu, and sigma with slope adjustment and sigma regularization.\n",
    "    \"\"\"\n",
    "    # Compute proportion of \"chose test\"\n",
    "    proportions = responses / levels\n",
    "    \n",
    "    # Perform linear regression to estimate slope and intercept\n",
    "    slope, intercept, _, _, _ = linregress(levels, proportions)\n",
    "    mu_guess = (0.5 - intercept) / slope\n",
    "\n",
    "    #print(slope, intercept)\n",
    "    lapse_rate_guess= 0.03  # 5% as a reasonable guess\n",
    "    sigma_guess= compute_sigma_from_slope(slope,lapse_rate_guess)-0.1\n",
    "\n",
    "    # Regularize sigma to avoid overestimation\n",
    "    intensity_range = np.abs(max(levels)) - np.abs(min(levels))\n",
    "    max_sigma = intensity_range * maxSigmaRatio\n",
    "    sigma_guess = min(sigma_guess, max_sigma)\n",
    "    #sigma_guess=sigma_guess/3\n",
    "    \n",
    "    return [lapse_rate_guess, mu_guess, sigma_guess]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 by 1 Psychometric Function fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard duration levels: [0.4997], Conflict levels: [-0.05, 0.0, 0.05], Noise levels: [0.0999, 1.1993]\n"
     ]
    }
   ],
   "source": [
    "conflictLeves=sorted(data['conflictDur'].unique())\n",
    "standardDurLevels=sorted(data['standardDur'].unique())\n",
    "noiseLevels=sorted(data['riseDur'].unique())\n",
    "print(f\"Standard duration levels: {standardDurLevels}, Conflict levels: {conflictLeves}, Noise levels: {noiseLevels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, standardLevel in enumerate(standardDurLevels):\n",
    "#     for j, noiseLevel in enumerate(noiseLevels):\n",
    "#         for k, conflictLevel in enumerate(conflictLeves):        \n",
    "#             #filter data\n",
    "#             df=data[data['conflictDur']==conflictLevel]\n",
    "#             df= df[df[\"standardDur\"]==standardLevel]\n",
    "#             df=df[df[\"riseDur\"]==noiseLevel]\n",
    "\n",
    "#             # select levels\n",
    "#             levels=df['avgAVDelta'].values\n",
    "#             responses=df['chose_test'].values\n",
    "#             # estimate initial guesses\n",
    "#             initial_guesses = estimateInitialGuessesRaw(levels, responses)\n",
    "               \n",
    "#             # fit psychometric function\n",
    "#             fitted_params = fitPsychometricRaw(levels, responses,initial_guesses)\n",
    "#             # print fitted parameters\n",
    "#             print(f\"Standard duration: {standardLevel}, Noise level: {noiseLevel}, Conflict level: {conflictLevel}, Fitted parameters: {fitted_params}\")\n",
    "\n",
    "#             # plot psychometric function\n",
    "#             plt.figure()\n",
    "#             plt.scatter(levels, responses, label='Data', color='blue')\n",
    "#             x = np.linspace(-0.9, 0.9, 100)\n",
    "#             y = psychometric_function(x, *fitted_params)\n",
    "#             plt.plot(x, y, label='Psychometric Function', color='red')\n",
    "#             plt.axvline(x=0, color='gray', linestyle='--',)\n",
    "#             plt.axhline(y=0.5, color='gray', linestyle='--')\n",
    "#             plt.xlabel('Delta Duration')\n",
    "#             plt.ylabel('Probability of Choosing Test')\n",
    "#             plt.title(f'Standard Duration: {standardLevel}, Noise Level: {noiseLevel}, Conflict Level: {conflictLevel}')\n",
    "#             # add fitted parameters to the plot\n",
    "#             plt.text(0.3, 0.2, f'lambda: {fitted_params[0]:.2f}\\nmu: {fitted_params[1]:.2f}\\nsigma: {fitted_params[2]:.2f}', fontsize=12, \n",
    "#                      bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "#             # # Binned data\n",
    "#             # binSize=8 # number of bins\n",
    "#             # binEdges = np.linspace(-0.9, 0.9, binSize + 1)\n",
    "#             # binCenters = 0.5 * (binEdges[:-1] + binEdges[1:])\n",
    "#             # binnedResponses = np.zeros(binSize)\n",
    "#             # binnedCounts = np.zeros(binSize)\n",
    "#             # for i in range(binSize):\n",
    "#             #     binMask = (levels >= binEdges[i]) & (levels < binEdges[i + 1])\n",
    "#             #     binnedResponses[i] = np.sum(responses[binMask])\n",
    "#             #     binnedCounts[i] = np.sum(binMask)\n",
    "#             # binnedProportions = binnedResponses / binnedCounts\n",
    "#             # # Plot each binCenter individually with marker size based on the number of responses\n",
    "#             # for binCenter, proportion, count in zip(binCenters, binnedProportions, binnedCounts):\n",
    "#             #     marker_size = (count / totalResponses + 0.5) * 100  # Adjust marker size based on count\n",
    "#             #     plt.scatter(binCenter, proportion, s=marker_size, color='green', label='Binned Data' if binCenter == binCenters[0] else \"\")\n",
    "#             # plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate data and fit psychometric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_and_plot(data, bin_method='cut', bins=10, bin_range=None, plot=True,color=\"blue\"):\n",
    "    if bin_method == 'cut':\n",
    "        data['bin'] = pd.cut(data[intensityVariable], bins=bins, labels=False, include_lowest=True, retbins=False)\n",
    "    elif bin_method == 'manual':\n",
    "        data['bin'] = np.digitize(data[intensityVariable], bins=bin_range) - 1\n",
    "    \n",
    "    grouped = data.groupby('bin').agg(\n",
    "        x_mean=(intensityVariable, 'mean'),\n",
    "        y_mean=('p_choose_test', 'mean'),\n",
    "        total_resp=('total_responses', 'sum')\n",
    "    )\n",
    "\n",
    "    if plot:\n",
    "        plt.scatter(grouped['x_mean'], grouped['y_mean'], s=grouped['total_resp']/data['total_responses'].sum()*900, color=color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fitting with initial guesses [0.0, -0.15, 0.05]: fit_psychometric_function() takes from 3 to 4 positional arguments but 6 were given\n",
      "Error fitting with initial guesses [0.0, -0.15, 1.0]: fit_psychometric_function() takes from 3 to 4 positional arguments but 6 were given\n",
      "Error fitting with initial guesses [0.0, 0.15, 0.05]: fit_psychometric_function() takes from 3 to 4 positional arguments but 6 were given\n",
      "Error fitting with initial guesses [0.0, 0.15, 1.0]: fit_psychometric_function() takes from 3 to 4 positional arguments but 6 were given\n",
      "Error fitting with initial guesses [0.2, -0.15, 0.05]: fit_psychometric_function() takes from 3 to 4 positional arguments but 6 were given\n",
      "Error fitting with initial guesses [0.2, -0.15, 1.0]: fit_psychometric_function() takes from 3 to 4 positional arguments but 6 were given\n",
      "Error fitting with initial guesses [0.2, 0.15, 0.05]: fit_psychometric_function() takes from 3 to 4 positional arguments but 6 were given\n",
      "Error fitting with initial guesses [0.2, 0.15, 1.0]: fit_psychometric_function() takes from 3 to 4 positional arguments but 6 were given\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Fit the psychometric function with multiple starting points\u001b[39;00m\n\u001b[1;32m     26\u001b[0m fitted_params \u001b[38;5;241m=\u001b[39m fitMultipleStartingPoints(levels, responses, totalResponses, multipleInitGuesses)\n\u001b[0;32m---> 27\u001b[0m fixedLapse\u001b[38;5;241m=\u001b[39m\u001b[43mfitted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# use fitted lapse rate\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLapse rate over all trials: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfitted_params[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1260x840 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(fig_w*3,fig_h*2))\n",
    "#plt.Subplot(3,2)\n",
    "\n",
    "# take over all trials psychometric curve to compute the lapse rate on experiment\n",
    "grouped=groupByChooseTest(data)\n",
    "levels=grouped[intensityVariable].values\n",
    "responses=grouped['num_of_chose_test'].values\n",
    "totalResponses=grouped['total_responses'].values\n",
    "# estimate init ial guesses\n",
    "initial_guesses = estimate_initial_guesses(levels, responses, totalResponses)\n",
    "# fit psychometric function\n",
    "# 100 random multiple starts\n",
    "multipleInitGuesses = []\n",
    "# 100 random multiple starts\n",
    "nStarts = 2\n",
    "initLambdas = np.linspace(0, 0.2, nStarts)  # Different initial guesses for lambda\n",
    "initMus = np.linspace(-0.15, 0.15, nStarts)  # Different initial guesses for mu\n",
    "initSigmas = np.linspace(0.05, 1, nStarts)  # Different initial guesses for sigma\n",
    "for initLambda in initLambdas:\n",
    "    for initMu in initMus:\n",
    "        for initSigma in initSigmas:\n",
    "            multipleInitGuesses.append([initLambda, initMu, initSigma])\n",
    "\n",
    "\n",
    "# Fit the psychometric function with multiple starting points\n",
    "fitted_params = fitMultipleStartingPoints(levels, responses, totalResponses, multipleInitGuesses)\n",
    "fixedLapse=fitted_params[0]  # use fitted lapse rate\n",
    "print(f\"Lapse rate over all trials: {fitted_params[0]:.2f}\")\n",
    "\n",
    "m=0\n",
    "for i, standardLevel in enumerate(standardDurLevels):\n",
    "    for j, noiseLevel in enumerate(noiseLevels):\n",
    "        m+=1        \n",
    "        df= data[data[\"standardDur\"]==standardLevel]\n",
    "        df=df[df[\"riseDur\"]==noiseLevel]\n",
    "        grouped=groupByChooseTest(df)\n",
    "        # p_choose_test\n",
    "        levels=grouped[intensityVariable].values\n",
    "        responses=grouped['num_of_chose_test'].values\n",
    "        totalResponses=grouped['total_responses'].values\n",
    "        # estimate initial guesses\n",
    "        initial_guesses = estimate_initial_guesses(levels, responses, totalResponses)\n",
    "        # fit psychometric function\n",
    "        #fitted_params = fit_psychometric_function(levels, responses, totalResponses,initial_guesses,fixedLapse=fixedLapse)\n",
    "        #fit with multiple starts\n",
    "        fitted_params = fitMultipleStartingPoints(levels, responses,totalResponses, multipleInitGuesses, fixedLapse=fixedLapse)\n",
    "        # print fitted parameters\n",
    "        print(f\"Standard duration: {standardLevel}, Noise level: {noiseLevel}, Fitted parameters: {fitted_params}\")\n",
    "\n",
    "        fixedSigma=fitted_params[1]  # use fitted sigma as fixed\n",
    "        print(f\"Sigma over noise level of {noiseLevel} trials: {fixedSigma:.2f}\")\n",
    "\n",
    "\n",
    "        for k, conflictLevel in enumerate(conflictLeves):\n",
    "            #filter data\n",
    "            df=data[data['conflictDur']==conflictLevel]\n",
    "            df= df[df[\"standardDur\"]==standardLevel]\n",
    "            df=df[df[\"riseDur\"]==noiseLevel]\n",
    "            grouped=groupByChooseTest(df)\n",
    "            # select levels\n",
    "            levels=grouped[intensityVariable].values\n",
    "            responses=grouped['num_of_chose_test'].values\n",
    "            totalResponses=grouped['total_responses'].values\n",
    "            #fixate the sigma and lapse rate and fit for mu\n",
    "            # fit psychometric function\n",
    "            #fittedMu = fit_psychometric_function(levels, responses, totalResponses,initial_guesses,fixedLapse=fixedLapse, fixedSigma=fixedSigma)\n",
    "            fittedMu= fitMultipleStartingPoints(levels, responses,totalResponses, multipleInitGuesses, fixedLapse=fixedLapse, fixedSigma=fixedSigma)\n",
    "            # print fitted parameters\n",
    "            print(f\"Conflict level: {conflictLevel}, Fitted parameters: {fittedMu}\")\n",
    "            # plot psychometric function\n",
    "            #plt.scatter(levels, responses/totalResponses, label='Data', color='blue')\n",
    "            plt.subplot(1,2,m)\n",
    "            maxX = max(levels) if len(levels) > 0 else 1.3  # Handle case with no levels\n",
    "            if maxX < 1.3:\n",
    "                maxX = 1.3\n",
    "            plt.xlim(-1, maxX)\n",
    "            plt.ylim(0, 1)\n",
    "            x = np.linspace(-1, maxX, 100)\n",
    "            y = psychometric_function(x, fixedLapse, fittedMu, fixedSigma)  # use fixed sigma\n",
    "            color=sns.color_palette(\"viridis\", as_cmap=True)(k / len(conflictLeves))  # Use a colormap for different conflict levels\n",
    "            plt.plot(x, y, label=round(conflictLevel, 2), color=color, linewidth=3)  # Plot the fitted psychometric function\n",
    "            plt.axvline(x=0, color='gray', linestyle='--',)\n",
    "            plt.axhline(y=0.5, color='gray', linestyle='--')\n",
    "            plt.xlabel('Physical duration difference (Comp-Standard avaraged sec)')\n",
    "            plt.ylabel('Probability of Choosing Test')\n",
    "            plt.title(f'Standard Auditory Duration: {round(standardLevel,2)}, Noise Level: {round(noiseLevel,2)}')\n",
    "            # add fitted parameters to the plot\n",
    "            # plt.text(0.3, 0.2, f'lambda: {fitted_params[0]:.2f}\\nmu: {fitted_params[1]:.2f}\\nsigma: {fitted_params[2]:.2f}', fontsize=12, \n",
    "            #          bbox=dict(facecolor='white', alpha=0.5))\n",
    "            plt.legend(title=\"Conflict Level\", fontsize=14, title_fontsize=14)\n",
    "            bin_and_plot(grouped, bin_method='cut', bins=8, plot=True,color=color)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wholesome Psychometric Function fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "estimate_initial_guesses() missing 2 required positional arguments: 'chooseTest' and 'totalResp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 130\u001b[0m\n\u001b[1;32m    127\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Call the function\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m \u001b[43mplot_psychometric_functions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Psychometric function fits when the data is pooled across all standard durations \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[120], line 45\u001b[0m, in \u001b[0;36mplot_psychometric_functions\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Filter the data by riseDur\u001b[39;00m\n\u001b[1;32m     43\u001b[0m X \u001b[38;5;241m=\u001b[39m aggregated_data[aggregated_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mriseDur\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m j]\n\u001b[0;32m---> 45\u001b[0m params_init \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_initial_guesses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# if np.abs(params_init[1])>0.5:\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#     params_init[1]=0\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStandard  of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms, Rise of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: estimate_initial_guesses() missing 2 required positional arguments: 'chooseTest' and 'totalResp'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x840 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import seed\n",
    "import random\n",
    "from scipy.stats import binned_statistic\n",
    "\n",
    "seed(10)\n",
    "# Generate a random hex color code\n",
    "def random_hex_color():\n",
    "    return \"#{:06x}\".format(random.randint(0, 0xFFFFFF))\n",
    "# Control color generation within a specific range (e.g., for pastel colors)\n",
    "def random_pastel_color():\n",
    "    return (random.uniform(0.6, 1), random.uniform(0.6, 1), random.uniform(0.6, 1))\n",
    "# Generate a random RGB tuple (values between 0 and 1)\n",
    "def random_rgb_color():\n",
    "    return (random.random(), random.random(), random.random())\n",
    "\n",
    "\n",
    "def plot_psychometric_functions(data):\n",
    "    fig, axs = plt.subplots(1,1, figsize=(12, 12))\n",
    "    fig.suptitle('Psychometric fits', fontsize=20)\n",
    "\n",
    "    #sort the data by standard duration\n",
    "    data = data.sort_values(by='standard_dur')\n",
    "    # fildering loop for each standard duration\n",
    "    for k, i in enumerate(data['standard_dur'].unique()):\n",
    "        # Filter data by standard duration\n",
    "        data_by_standard = data[data['standard_dur'] == i].copy()\n",
    "\n",
    "        # Group data by avgAVDelta and riseDur\n",
    "        aggregated_data = data_by_standard.groupby(['avgAVDelta', 'riseDur']).agg(\n",
    "                num_of_chose_test=('chose_test', 'sum'),\n",
    "                total_responses=('responses', 'count'),\n",
    "        ).reset_index()\n",
    "        # Calculate the probability of choosing the test\n",
    "        aggregated_data['p_choose_test'] = aggregated_data['num_of_chose_test'] / aggregated_data['total_responses']\n",
    "        # sort the values\n",
    "        aggregated_data = aggregated_data.sort_values(by='riseDur')\n",
    "        # select each riseDur and fit the psychometric function\n",
    "        for j in aggregated_data['riseDur'].unique():\n",
    "            #lineStyle = '--' if j == 0.80 else '-'  # Different line style for riseDur=0.050\n",
    "            #lineColor = 'darkgreen' if j == 4.5 else 'orange'  # Different line color for riseDur=0.050\n",
    "            lineColor=random_rgb_color()\n",
    "            # Filter the data by riseDur\n",
    "            X = aggregated_data[aggregated_data['riseDur'] == j]\n",
    "   \n",
    "            params_init = estimate_initial_guesses(X)\n",
    "            # if np.abs(params_init[1])>0.5:\n",
    "            #     params_init[1]=0\n",
    "\n",
    "            print(f'Standard  of {i}s, Rise of {j}s')\n",
    "            print(f\"Initial guesses: {params_init[0]:.3f}, {params_init[1]:.3f}, {params_init[2]:.3f}\")\n",
    "            lambda_hat, mu_hat, sigma_hat = fit_psychometric_function(X,init_guesses=params_init) # Fit psychometric function\n",
    "\n",
    "            print(f\"Fitted parameters Î»: {lambda_hat:.3f}, Î¼: {mu_hat:.3f}, Ïƒ: {sigma_hat:.3f}\")\n",
    "\n",
    "            x_data = X['avgAVDelta']\n",
    "            y_data = X['p_choose_test']\n",
    "                        \n",
    "            # # Normalize bin sizes for scatter plot\n",
    "            #ax = axs[k // 2, k % 2]\n",
    "            X=X.sort_values(by='avgAVDelta')\n",
    "            # bin_size=10\n",
    "            # bin_distance=0.3\n",
    "            # x_data=X['avgAVDelta']\n",
    "            # y_data=X['p_choose_test']\n",
    "            total_bins=X['total_responses']\n",
    "\n",
    "            # for m in np.linspace(min(X['avgAVDelta']),max(X['avgAVDelta']),bin_size):\n",
    "            #         # search for values +- 0.2 of the i value\n",
    "            #         mask=(x_data>=m-bin_distance) & (x_data<m+bin_distance)\n",
    "            #         # get the mean of the values\n",
    "            #         x_mean=np.mean(x_data[mask])\n",
    "            #         y_mean=np.mean(y_data[mask])\n",
    "            #         # get the total responses\n",
    "            #         total_resp=np.sum(total_bins[mask])\n",
    "            #         # plot the mean values\n",
    "            #         plt.plot(x_mean,y_mean,'o',markersize=((total_resp/np.sum(total_bins)+0.3)*20),color=lineColor)\n",
    "            \n",
    "            #Binning using pd.Cut \n",
    "            bin_size = 8  # Number of bins\n",
    "            # Create bins\n",
    "            X['bin'] = pd.cut(X['avgAVDelta'], bins=bin_size, labels=False, retbins=False, include_lowest=True)\n",
    "            # Calculate means and sums within each bin\n",
    "            bin_group = X.groupby('bin').agg(\n",
    "                x_mean=('avgAVDelta', 'mean'),\n",
    "                y_mean=('p_choose_test', 'mean'),\n",
    "                total_resp=('total_responses', 'sum') )\n",
    "            \n",
    "            # Total responses for normalization of marker size\n",
    "            total_responses = X['total_responses'].sum()\n",
    "            # Plotting\n",
    "            for index, row in bin_group.iterrows():\n",
    "                marker_size = (row['total_resp'] / total_responses +0.5) * 20\n",
    "                plt.plot(row['x_mean'], row['y_mean'],'o',markersize=marker_size,color=lineColor)\n",
    "            \n",
    "\n",
    "            # # binning using np.histogram\n",
    "            # bin_size=6\n",
    "            # bin_edges = [-0.8 -0.5,-0.3 -0.1, 0, 0.1, 0.3, 0.5, 0.8]\n",
    "\n",
    "            # hist, bin_edges = np.histogram(X['avgAVDelta'], bins=bin_edges)    \n",
    "            # bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "            # # Calculate the mean of y_data for each bin\n",
    "            # y_means = [np.mean(y_data[(x_data >= bin_edges[i]) & (x_data < bin_edges[i + 1])]) for i in range(len(bin_edges) - 1)]\n",
    "            # # Calculate the total responses for each bin\n",
    "            # total_bins = [np.sum(total_bins[(x_data >= bin_edges[i]) & (x_data < bin_edges[i + 1])]) for i in range(len(bin_edges) - 1)]\n",
    "            # # Normalize the marker size\n",
    "            # total_responses = np.sum(total_bins)\n",
    "            # for i in range(len(bin_centers)):\n",
    "            #     marker_size = (total_bins[i] / total_responses + 0.5) * 20\n",
    "            #     plt.plot(bin_centers[i], y_means[i],'o',markersize=marker_size,color=lineColor) \n",
    "                           \n",
    "            # Plot the psychometric function\n",
    "            x_fit = np.linspace(min(X['avgAVDelta']),max(X['avgAVDelta']), 1000)\n",
    "            y_fit = psychometric_function(x_fit, lambda_hat, mu_hat, sigma_hat)\n",
    "            plt.plot(x_fit, y_fit, label=f'Rise= {j}\\n Î»={lambda_hat:.2f}\\n Î¼={mu_hat:.2f}\\n Ïƒ={sigma_hat:.2f}', alpha=0.9,color=lineColor)\n",
    "                     #linestyle=lineStyle, color=lineColor,)\n",
    "            # scatter raw data\n",
    "            plt.scatter(x_data, y_data, s=X['total_responses']*30, color=lineColor, alpha=0.2)\n",
    "            plt.vlines(x=0, ymin=0, ymax=1, linestyles='dashed', colors='gray',alpha=0.5)   \n",
    "            plt.hlines(y=0.5, xmin=min(X['avgAVDelta']), xmax=max(X['avgAVDelta']), linestyles='dashed', colors='gray',alpha=0.5)\n",
    "            plt.xlabel('Delta duration percent (% of standard)')\n",
    "            plt.ylabel('P(chose test)')\n",
    "            plt.title(f'Test longer for Standard of {i}s')\n",
    "            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "plot_psychometric_functions(data)\n",
    "# Psychometric function fits when the data is pooled across all standard durations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mathmod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
