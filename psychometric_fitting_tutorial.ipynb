{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb795c8",
   "metadata": {},
   "source": [
    "# Psychometric Function Fitting Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the refactored `psychometric_model.py` module for fitting psychometric functions to duration discrimination data. The refactored code eliminates global variable dependencies and provides a clean, object-oriented interface suitable for Jupyter notebooks.\n",
    "\n",
    "## Key Improvements\n",
    "\n",
    "- **No Global Variables**: All functions now accept required parameters explicitly\n",
    "- **Class-Based Design**: `PsychometricModel` class encapsulates configuration and methods\n",
    "- **Modular Functions**: Easy to import and use in different contexts\n",
    "- **Robust Parameter Handling**: Clear separation of model configuration and data processing\n",
    "\n",
    "Let's start by importing the necessary libraries and our refactored module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from psychometric_model import PsychometricModel, load_data_simple\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "print(\"✅ Imports successful! Ready to fit psychometric functions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2832ff1c",
   "metadata": {},
   "source": [
    "## Section 1: Refactor Global Variables to Function Arguments\n",
    "\n",
    "The original `fitMain.py` had issues with global variables like `allIndependent`, `nLambda`, `nSigma`, `uniqueSensory`, and `uniqueConflict` that caused import problems. \n",
    "\n",
    "**Problems with the original approach:**\n",
    "- Functions relied on global state\n",
    "- Importing functions in other files caused \"variable not defined\" errors\n",
    "- Hard to reuse code in different contexts\n",
    "- Configuration was scattered throughout the code\n",
    "\n",
    "**Our solution:**\n",
    "- All functions now accept required variables as explicit arguments\n",
    "- Configuration is stored in a class instance\n",
    "- No global state dependencies\n",
    "- Clean, modular interface\n",
    "\n",
    "Let's see how this works by creating a model instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb8c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different model configurations\n",
    "\n",
    "# Configuration 1: All independent parameters (each condition gets its own λ, μ, σ)\n",
    "model_independent = PsychometricModel(all_independent=True, shared_sigma=False)\n",
    "print(f\"Independent model: all_independent={model_independent.all_independent}, shared_sigma={model_independent.shared_sigma}\")\n",
    "\n",
    "# Configuration 2: Shared sigma across conditions  \n",
    "model_shared_sigma = PsychometricModel(all_independent=False, shared_sigma=True)\n",
    "print(f\"Shared sigma model: all_independent={model_shared_sigma.all_independent}, shared_sigma={model_shared_sigma.shared_sigma}\")\n",
    "\n",
    "# Configuration 3: Shared lambda only\n",
    "model_shared_lambda = PsychometricModel(all_independent=False, shared_sigma=False)\n",
    "print(f\"Shared lambda model: all_independent={model_shared_lambda.all_independent}, shared_sigma={model_shared_lambda.shared_sigma}\")\n",
    "\n",
    "print(\"\\n✅ Model configurations created successfully!\")\n",
    "print(\"📝 Notice: No global variables needed - all configuration is stored in the class instance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bb34b7",
   "metadata": {},
   "source": [
    "## Section 2: Encapsulate Model Fitting in a Class\n",
    "\n",
    "The `PsychometricModel` class stores all configuration and provides clean methods for:\n",
    "\n",
    "- **Data loading and preprocessing** (`load_data`)\n",
    "- **Grouping and aggregating responses** (`group_by_choose_test`) \n",
    "- **Parameter estimation** (`estimate_initial_guesses`)\n",
    "- **Model fitting** (`fit_multiple_starting_points`)\n",
    "- **Parameter extraction** (`get_params`)\n",
    "- **Visualization** (`plot_fitted_psychometric`)\n",
    "\n",
    "**Benefits of the class-based approach:**\n",
    "- All related functionality is grouped together\n",
    "- Configuration is stored as instance attributes\n",
    "- Methods can access instance state\n",
    "- Easy to create multiple models with different settings\n",
    "- No global variable pollution\n",
    "\n",
    "Let's load some data and see the class in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb915281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model instance for demonstration\n",
    "model = PsychometricModel(all_independent=False, shared_sigma=False)\n",
    "\n",
    "# For this example, let's create some synthetic data\n",
    "# In practice, you would load your actual data file like this:\n",
    "# data, data_name = model.load_data(\"your_data_file.csv\")\n",
    "\n",
    "# Create synthetic data for demonstration\n",
    "np.random.seed(42)\n",
    "n_trials_per_condition = 50\n",
    "\n",
    "# Create conditions\n",
    "noise_levels = [0.1, 1.2]\n",
    "conflict_levels = [0.0, 0.1, 0.2]\n",
    "delta_durs = np.linspace(-0.4, 0.4, 9)\n",
    "\n",
    "synthetic_data = []\n",
    "for noise in noise_levels:\n",
    "    for conflict in conflict_levels:\n",
    "        for delta in delta_durs:\n",
    "            # Simulate psychometric response\n",
    "            true_mu = conflict * 0.3  # Some bias due to conflict\n",
    "            true_sigma = 0.1 if noise > 1.0 else 0.2  # Higher noise = worse discrimination\n",
    "            \n",
    "            p_choose_test = 0.02 + 0.96 * (1 / (1 + np.exp(-(delta - true_mu) / true_sigma)))\n",
    "            \n",
    "            for trial in range(n_trials_per_condition):\n",
    "                chose_test = np.random.binomial(1, p_choose_test)\n",
    "                \n",
    "                synthetic_data.append({\n",
    "                    'audNoise': noise,\n",
    "                    'conflictDur': conflict,\n",
    "                    'standardDur': 0.5,\n",
    "                    'testDurS': 0.5 + delta,\n",
    "                    'deltaDurS': delta,\n",
    "                    'responses': np.random.choice([0, 1]),\n",
    "                    'order': chose_test,\n",
    "                    'recordedDurVisualStandard': 0.5 + conflict,\n",
    "                    'recordedDurVisualTest': 0.5 + delta + conflict,\n",
    "                })\n",
    "\n",
    "data = pd.DataFrame(synthetic_data)\n",
    "\n",
    "# Set up the model's unique values (normally done by load_data)\n",
    "model.unique_sensory = data['audNoise'].unique()\n",
    "model.unique_conflict = sorted(data['conflictDur'].unique())\n",
    "model.unique_standard = data['standardDur'].unique()\n",
    "model.n_lambda = len(model.unique_standard)\n",
    "model.n_sigma = len(model.unique_sensory)\n",
    "\n",
    "# Add response columns\n",
    "data['chose_test'] = (data['responses'] == data['order']).astype(int)\n",
    "data['chose_standard'] = (data['responses'] != data['order']).astype(int)\n",
    "\n",
    "print(f\"✅ Created synthetic dataset with {len(data)} trials\")\n",
    "print(f\"Noise levels: {model.unique_sensory}\")\n",
    "print(f\"Conflict levels: {model.unique_conflict}\")\n",
    "print(f\"Model configuration: all_independent={model.all_independent}, shared_sigma={model.shared_sigma}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc859d9",
   "metadata": {},
   "source": [
    "## Section 3: Update getParams and Related Functions to Use Class Attributes\n",
    "\n",
    "The original `getParams` function had several issues:\n",
    "- It relied on global variables like `uniqueSensory`, `uniqueConflict`\n",
    "- It used hardcoded variable names from global scope\n",
    "- It was difficult to use outside the original script\n",
    "\n",
    "**Our improved approach:**\n",
    "- `get_params` is now a method of the `PsychometricModel` class\n",
    "- It uses instance attributes (`self.unique_sensory`, `self.unique_conflict`, etc.)\n",
    "- It handles different parameter configurations cleanly\n",
    "- All related functions (`negative_log_likelihood_joint`, `fit_joint`) follow the same pattern\n",
    "\n",
    "Let's see how the improved parameter extraction works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f78a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the improved parameter extraction\n",
    "# First, let's create some example parameters for our model configuration\n",
    "\n",
    "if model.all_independent:\n",
    "    # Each condition gets its own lambda, mu, sigma\n",
    "    n_conditions = len(model.unique_sensory) * len(model.unique_conflict)\n",
    "    example_params = np.array([0.05, -0.1, 0.15] * n_conditions)  # [lambda, mu, sigma] repeated\n",
    "else:\n",
    "    # Shared lambda configuration\n",
    "    n_conditions = len(model.unique_sensory) * len(model.unique_conflict)\n",
    "    example_params = np.concatenate([\n",
    "        [0.05],  # shared lambda\n",
    "        np.linspace(-0.2, 0.2, n_conditions),  # mu for each condition\n",
    "        np.linspace(0.1, 0.3, n_conditions)   # sigma for each condition\n",
    "    ])\n",
    "\n",
    "print(f\"Example parameter vector: {example_params}\")\n",
    "print(f\"Parameter vector length: {len(example_params)}\")\n",
    "\n",
    "# Test parameter extraction for different conditions\n",
    "print(\"\\n🔍 Testing parameter extraction:\")\n",
    "for noise in model.unique_sensory:\n",
    "    for conflict in model.unique_conflict:\n",
    "        try:\n",
    "            lambda_, mu, sigma = model.get_params(example_params, conflict, noise)\n",
    "            print(f\"  Noise={noise}, Conflict={conflict}: λ={lambda_:.3f}, μ={mu:.3f}, σ={sigma:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error for Noise={noise}, Conflict={conflict}: {e}\")\n",
    "\n",
    "print(\"\\n✅ Parameter extraction working correctly!\")\n",
    "print(\"📝 Notice: No global variables needed - all data comes from class attributes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97525aa",
   "metadata": {},
   "source": [
    "## Section 4: Rewrite fitMultipleStartingPoints for Notebook Use\n",
    "\n",
    "The original `fitMultipleStartingPoints` function had several limitations:\n",
    "- Required many global variables to be set beforehand\n",
    "- Hard to use in interactive contexts\n",
    "- Parameter configuration was scattered\n",
    "- No clear separation between data processing and model fitting\n",
    "\n",
    "**Our improved method:**\n",
    "- `fit_multiple_starting_points` is now a class method\n",
    "- All configuration is stored in the instance\n",
    "- Returns fit results suitable for further analysis\n",
    "- Works seamlessly in notebook environments\n",
    "- Stores fitted parameters in the instance for later use\n",
    "\n",
    "Let's fit our model and see the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec77546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to our data\n",
    "print(\"🔄 Fitting psychometric model...\")\n",
    "print(f\"Model configuration: all_independent={model.all_independent}, shared_sigma={model.shared_sigma}\")\n",
    "\n",
    "try:\n",
    "    # Fit with multiple starting points for robust optimization\n",
    "    fit_result = model.fit_multiple_starting_points(data, n_start=3)\n",
    "    \n",
    "    print(f\"✅ Model fitting completed successfully!\")\n",
    "    print(f\"Final negative log-likelihood: {fit_result.fun:.2f}\")\n",
    "    print(f\"Optimization success: {fit_result.success}\")\n",
    "    print(f\"Number of fitted parameters: {len(fit_result.x)}\")\n",
    "    \n",
    "    # The fitted parameters are now stored in the model instance\n",
    "    print(f\"Fitted parameters: {model.fitted_params[:6]}...\")  # Show first 6 parameters\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Fitting failed: {e}\")\n",
    "    \n",
    "# Let's also examine the grouped data that was used for fitting\n",
    "grouped_data = model.group_by_choose_test(data)\n",
    "print(f\"\\n📊 Data summary:\")\n",
    "print(f\"Number of conditions: {len(grouped_data)}\")\n",
    "print(f\"Total responses: {grouped_data['total_responses'].sum()}\")\n",
    "print(f\"Proportion choosing test range: {grouped_data['p_choose_test'].min():.2f} - {grouped_data['p_choose_test'].max():.2f}\")\n",
    "\n",
    "# Show a sample of the grouped data\n",
    "print(f\"\\nSample of grouped data:\")\n",
    "print(grouped_data[['audNoise', 'conflictDur', 'deltaDurS', 'num_of_chose_test', 'total_responses', 'p_choose_test']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e42e1",
   "metadata": {},
   "source": [
    "## Section 5: Provide Example Usage in Jupyter Notebook Cells\n",
    "\n",
    "Now let's demonstrate the complete workflow for using the refactored code in a Jupyter notebook. This shows how easy it is to:\n",
    "\n",
    "1. **Import the module** without worrying about global variables\n",
    "2. **Create model instances** with different configurations  \n",
    "3. **Load and process data** using class methods\n",
    "4. **Fit models** with robust optimization\n",
    "5. **Visualize results** with integrated plotting\n",
    "6. **Analyze parameters** with convenient summary methods\n",
    "\n",
    "### Workflow Example: Complete Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24339a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the fitted psychometric functions\n",
    "print(\"📈 Creating psychometric function plots...\")\n",
    "\n",
    "# Plot the fitted curves with data points\n",
    "model.plot_fitted_psychometric(data, title_prefix=\"Duration Discrimination\")\n",
    "\n",
    "# The plot will show:\n",
    "# - Fitted psychometric curves for each condition\n",
    "# - Data points binned for visualization  \n",
    "# - Parameter values for each condition\n",
    "# - Separate subplots for different noise levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f16a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a summary of fitted parameters\n",
    "print(\"📋 Parameter Summary\")\n",
    "parameter_summary = model.get_parameter_summary()\n",
    "print(parameter_summary)\n",
    "\n",
    "# Analyze parameter patterns\n",
    "print(\"\\n🔍 Parameter Analysis:\")\n",
    "\n",
    "# Lambda (lapse rate) analysis\n",
    "lambdas = parameter_summary['lambda'].values\n",
    "print(f\"Lapse rate (λ): mean = {np.mean(lambdas):.3f}, std = {np.std(lambdas):.3f}\")\n",
    "\n",
    "# Mu (bias) analysis by conflict\n",
    "for conflict in model.unique_conflict:\n",
    "    conflict_data = parameter_summary[parameter_summary['conflict_level'] == conflict]\n",
    "    mus = conflict_data['mu'].values\n",
    "    print(f\"Bias (μ) for conflict {conflict}: mean = {np.mean(mus):.3f}, std = {np.std(mus):.3f}\")\n",
    "\n",
    "# Sigma (sensitivity) analysis by noise\n",
    "for noise in model.unique_sensory:\n",
    "    noise_data = parameter_summary[parameter_summary['noise_level'] == noise]\n",
    "    sigmas = noise_data['sigma'].values\n",
    "    print(f\"Sensitivity (σ) for noise {noise}: mean = {np.mean(sigmas):.3f}, std = {np.std(sigmas):.3f}\")\n",
    "\n",
    "print(f\"\\n✅ Analysis complete!\")\n",
    "print(f\"💡 The model successfully captured the expected patterns:\")\n",
    "print(f\"   - Higher conflict → increased bias (μ)\")\n",
    "print(f\"   - Higher noise → decreased sensitivity (larger σ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8c8d2",
   "metadata": {},
   "source": [
    "### Comparing Different Model Configurations\n",
    "\n",
    "One of the key advantages of the refactored code is that you can easily compare different model configurations. Let's fit the same data with different parameter sharing schemes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b511e170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different model configurations\n",
    "models_to_compare = {\n",
    "    'Independent': PsychometricModel(all_independent=True, shared_sigma=False),\n",
    "    'Shared Lambda': PsychometricModel(all_independent=False, shared_sigma=False), \n",
    "    'Shared Sigma': PsychometricModel(all_independent=False, shared_sigma=True)\n",
    "}\n",
    "\n",
    "comparison_results = {}\n",
    "\n",
    "for name, model_config in models_to_compare.items():\n",
    "    print(f\"\\n🔄 Fitting {name} model...\")\n",
    "    \n",
    "    # Set up the model configuration\n",
    "    model_config.unique_sensory = data['audNoise'].unique()\n",
    "    model_config.unique_conflict = sorted(data['conflictDur'].unique())\n",
    "    model_config.unique_standard = data['standardDur'].unique()\n",
    "    model_config.n_lambda = len(model_config.unique_standard)\n",
    "    model_config.n_sigma = len(model_config.unique_sensory)\n",
    "    \n",
    "    try:\n",
    "        fit_result = model_config.fit_multiple_starting_points(data, n_start=2)\n",
    "        comparison_results[name] = {\n",
    "            'model': model_config,\n",
    "            'nll': fit_result.fun,\n",
    "            'n_params': len(fit_result.x),\n",
    "            'success': fit_result.success\n",
    "        }\n",
    "        print(f\"  ✅ {name}: NLL = {fit_result.fun:.2f}, {len(fit_result.x)} parameters\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ {name} failed: {e}\")\n",
    "        comparison_results[name] = {'model': model_config, 'nll': np.inf, 'n_params': 0, 'success': False}\n",
    "\n",
    "# Calculate AIC for model comparison\n",
    "print(f\"\\n📊 Model Comparison (AIC - lower is better):\")\n",
    "for name, result in comparison_results.items():\n",
    "    if result['success']:\n",
    "        aic = 2 * result['n_params'] + 2 * result['nll']\n",
    "        print(f\"  {name}: AIC = {aic:.1f} (NLL = {result['nll']:.1f}, {result['n_params']} params)\")\n",
    "    else:\n",
    "        print(f\"  {name}: Failed to fit\")\n",
    "\n",
    "# Find best model\n",
    "best_model = min([name for name, result in comparison_results.items() if result['success']], \n",
    "                key=lambda name: 2 * comparison_results[name]['n_params'] + 2 * comparison_results[name]['nll'])\n",
    "\n",
    "print(f\"\\n🏆 Best model: {best_model}\")\n",
    "print(f\"💡 The refactored code makes it easy to compare different model configurations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72998de",
   "metadata": {},
   "source": [
    "## Summary: Benefits of the Refactored Code\n",
    "\n",
    "### ✅ Problems Solved\n",
    "\n",
    "1. **No More Global Variable Errors**: Functions no longer rely on `allIndependent`, `nLambda`, `uniqueSensory`, etc. being defined globally\n",
    "2. **Easy Imports**: You can now `from psychometric_model import PsychometricModel` without issues\n",
    "3. **Clean Interfaces**: All configuration is explicit and contained within class instances\n",
    "4. **Modular Design**: Each component has a clear responsibility and can be used independently\n",
    "\n",
    "### 🚀 Key Improvements\n",
    "\n",
    "- **Class-Based Architecture**: `PsychometricModel` encapsulates all functionality\n",
    "- **Explicit Parameter Passing**: No hidden dependencies on global state\n",
    "- **Instance Attributes**: Configuration stored cleanly in `self.unique_sensory`, `self.n_lambda`, etc.\n",
    "- **Method Chaining**: Load data → Fit model → Plot results in a clean pipeline\n",
    "- **Multiple Configurations**: Easy to create and compare different model variants\n",
    "\n",
    "### 📝 Usage Guidelines for Jupyter Notebooks\n",
    "\n",
    "**Basic workflow:**\n",
    "```python\n",
    "# 1. Import and create model\n",
    "from psychometric_model import PsychometricModel\n",
    "model = PsychometricModel(all_independent=False, shared_sigma=True)\n",
    "\n",
    "# 2. Load data (or set up manually for synthetic data)\n",
    "data, name = model.load_data(\"your_data.csv\")\n",
    "\n",
    "# 3. Fit model\n",
    "fit_result = model.fit_multiple_starting_points(data, n_start=5)\n",
    "\n",
    "# 4. Visualize and analyze\n",
    "model.plot_fitted_psychometric(data)\n",
    "parameter_summary = model.get_parameter_summary()\n",
    "```\n",
    "\n",
    "**For parameter comparisons:**\n",
    "```python\n",
    "# Easy to compare different configurations\n",
    "models = {\n",
    "    'independent': PsychometricModel(True, False),\n",
    "    'shared_lambda': PsychometricModel(False, False),\n",
    "    'shared_sigma': PsychometricModel(False, True)\n",
    "}\n",
    "```\n",
    "\n",
    "### 🎯 Next Steps\n",
    "\n",
    "You can now:\n",
    "- Import this module in any Python script or notebook\n",
    "- Create multiple model instances with different configurations\n",
    "- Fit models without worrying about global variable conflicts\n",
    "- Easily extend the functionality by adding new methods to the class\n",
    "- Use the code as a foundation for more complex psychometric modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d95645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: How to use with real data files\n",
    "\n",
    "print(\"📁 Example: Loading Real Data\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# This is how you would load and analyze your actual data files:\n",
    "\n",
    "example_usage = '''\n",
    "# Import the module\n",
    "from psychometric_model import PsychometricModel\n",
    "\n",
    "# Create a model instance  \n",
    "model = PsychometricModel(all_independent=False, shared_sigma=True)\n",
    "\n",
    "# Load your data file\n",
    "data, data_name = model.load_data(\"dt_all.csv\")  # Your actual data file\n",
    "\n",
    "# Fit the model with multiple starting points for robustness\n",
    "fit_result = model.fit_multiple_starting_points(data, n_start=5)\n",
    "\n",
    "# Visualize results\n",
    "model.plot_fitted_psychometric(data, title_prefix=data_name)\n",
    "\n",
    "# Get parameter summary\n",
    "params_df = model.get_parameter_summary()\n",
    "print(params_df)\n",
    "\n",
    "# Access fitted parameters for further analysis\n",
    "fitted_params = model.fitted_params\n",
    "print(f\"Fitted parameters: {fitted_params}\")\n",
    "'''\n",
    "\n",
    "print(\"Example code for real data analysis:\")\n",
    "print(example_usage)\n",
    "\n",
    "print(\"\"\"\n",
    "🎉 Congratulations! You now have a fully modular, notebook-friendly \n",
    "psychometric fitting library that solves all the global variable issues \n",
    "from the original fitMain.py code.\n",
    "\n",
    "Key benefits:\n",
    "✅ No more \"variable not defined\" errors when importing\n",
    "✅ Clean, object-oriented interface\n",
    "✅ Easy to use in Jupyter notebooks  \n",
    "✅ Configurable model architectures\n",
    "✅ Robust optimization with multiple starting points\n",
    "✅ Integrated visualization and analysis tools\n",
    "\n",
    "Happy modeling! 🧠📊\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
