{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4293cb8",
   "metadata": {},
   "source": [
    "# Simulation of Audio-Visual Duration Estimation with Causal Inference Model\n",
    "This notebook simulates the audio-visual duration estimation task using a causal inference model. It allows you to explore how different parameters affect the estimates through interactive controls.\n",
    "### Experimenter knows the true durations:\n",
    "Standard duration($S_s$) is always 0.5s, test duration varies($S_t$).\n",
    "We simulate and give the parameters to the model, and see how the estimates change.\n",
    "Parameters:\n",
    "- $\\sigma_a$: Standard deviation of auditory measurement noise\n",
    "- $\\sigma_v$: Standard deviation of visual measurement noise\n",
    "- $p_c$: Prior probability of common cause\n",
    "### Parameters we dont need to adjust specifically:\n",
    "- $c$: Conflict level between auditory and visual stimuli\n",
    "- $tmin$ and $tmax$: Minimum and maximum test durations\n",
    "\n",
    "### Steps:\n",
    "1. Create and repeated array of standard durations: S_s: [0.5, 0.5, ..., 0.5]\n",
    "2. Create an array of duration differences: delta: [0.0, 0.1, ..., 2.0]\n",
    "3. Create constant conflict durations: c:[-250,-167,-83,0,83,167,250]ms\n",
    "4. For each combination of S_s, delta, and c:\n",
    "    - Calculate test duration: S_t = S_s + delta + c\n",
    "5. For simplicity we dont need to estimate noisy measurements, we can directly use the true durations as measurements.\n",
    "6. Use the causal inference model to compute the final estimates based on the measurements and parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1bc3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lbraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, lognorm, gaussian_kde\n",
    "from ipywidgets import interact, FloatSlider, widgets\n",
    "from scipy.special import expit  # Sigmoid function for probability mapping\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4979d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simulation of Audio-Visual Duration Estimation with Causal Inference Model This notebook simulates the audio-visual duration estimation task using a causal inference model. It allows you to explore how different parameters affect the estimates through interactive controls. ### Experimenter knows the true durations: Standard duration($S_s$) is always 0.5s, test duration varies($S_t$). We simulate and give the parameters to the model, and see how the estimates change. Parameters: - $\\sigma_a$: Standard deviation of auditory measurement noise - $\\sigma_v$: Standard deviation of visual measurement noise - $p_c$: Prior probability of common cause ### Parameters we dont need to adjust specifically: - $c$: Conflict level between auditory and visual stimuli - $\\tmin$ and $\\tmax$: Minimum and maximum test durations ### Steps: 1. Create and repeated array of standard durations: S_s: [0.5, 0.5, ..., 0.5] 2. Create an array of duration differences: delta: [0.0, 0.1, ..., 2.0] 3. Create constant conflict durations: c:[-250,-167,-83,0,83,167,250]ms 4. For each combination of S_s, delta, and c: - Calculate test duration: S_t = S_s + delta + c 5. For simplicity we dont need to estimate noisy measurements, we can directly use the true durations as measurements. 6. Use the causal inference model to compute the final estimates based on the measurements and parameters.\n",
    "# Standard durations of auditory stimuli\n",
    "S_a_s = 0.5  # seconds\n",
    "# repeat\n",
    "S_a_s = np.repeat(S_a_s, 9990)\n",
    "# Range of test durations (difference from standard) -100% to +100%\n",
    "delta_percent = np.linspace(-0.95, 0.95, 7)  # -100% to +100%\n",
    "# Convert percentage differences to absolute time differences (in seconds)\n",
    "delta = delta_percent * S_a_s[0]  # since S_a_s is constant\n",
    "# Constant conflict levels (in seconds)\n",
    "c = np.array([-0.45,-0.35, -0.25, -0.167, -0.083, 0.0, 0.083, 0.167, 0.25, 0.35,+0.45])  # seconds\n",
    "\n",
    "# Ensure all arrays have the same length\n",
    "min_length = min(len(S_a_s), len(delta) * (len(S_a_s) // len(delta)), len(c) * (len(S_a_s) // len(c)))\n",
    "S_a_s = S_a_s[:min_length]\n",
    "delta = np.tile(delta, int(np.ceil(len(S_a_s) / len(delta))))[:min_length]\n",
    "c = np.tile(c, int(np.ceil(len(S_a_s) / len(c))))[:min_length]\n",
    "\n",
    "# Calculate test durations\n",
    "S_a_t = S_a_s + delta \n",
    "S_v_s = S_a_s + c  # Visual test durations with conflict\n",
    "S_v_t = S_a_t # no conflict in test durations for visual\n",
    "# Combine standard and test durations, delta, and conflict into a single dataset\n",
    "simData=np.column_stack((S_a_s, S_a_t, S_v_s, S_v_t, delta, c))\n",
    "# Columns: [S_a_s, S_a_t, S_v_s, S_v_t, delta, c]\n",
    "\n",
    "# create a dataframe\n",
    "import pandas as pd\n",
    "simData = pd.DataFrame(simData, columns=['S_a_s', 'S_a_t', 'S_v_s', 'S_v_t', 'delta', 'c'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a479f150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "S_a_s",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "S_a_t",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "S_v_s",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "S_v_t",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "c",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2498eca9-3e76-491d-a4f6-c1549b947f41",
       "rows": [
        [
         "0",
         "0.5",
         "0.025000000000000022",
         "0.04999999999999999",
         "0.025000000000000022",
         "-0.475",
         "-0.45"
        ],
        [
         "1",
         "0.5",
         "0.18333333333333335",
         "0.15000000000000002",
         "0.18333333333333335",
         "-0.31666666666666665",
         "-0.35"
        ],
        [
         "2",
         "0.5",
         "0.3416666666666667",
         "0.25",
         "0.3416666666666667",
         "-0.15833333333333333",
         "-0.25"
        ],
        [
         "3",
         "0.5",
         "0.5",
         "0.33299999999999996",
         "0.5",
         "0.0",
         "-0.167"
        ],
        [
         "4",
         "0.5",
         "0.6583333333333333",
         "0.417",
         "0.6583333333333333",
         "0.15833333333333333",
         "-0.083"
        ],
        [
         "5",
         "0.5",
         "0.8166666666666667",
         "0.5",
         "0.8166666666666667",
         "0.31666666666666665",
         "0.0"
        ],
        [
         "6",
         "0.5",
         "0.975",
         "0.583",
         "0.975",
         "0.475",
         "0.083"
        ],
        [
         "7",
         "0.5",
         "0.025000000000000022",
         "0.667",
         "0.025000000000000022",
         "-0.475",
         "0.167"
        ],
        [
         "8",
         "0.5",
         "0.18333333333333335",
         "0.75",
         "0.18333333333333335",
         "-0.31666666666666665",
         "0.25"
        ],
        [
         "9",
         "0.5",
         "0.3416666666666667",
         "0.85",
         "0.3416666666666667",
         "-0.15833333333333333",
         "0.35"
        ],
        [
         "10",
         "0.5",
         "0.5",
         "0.95",
         "0.5",
         "0.0",
         "0.45"
        ],
        [
         "11",
         "0.5",
         "0.6583333333333333",
         "0.04999999999999999",
         "0.6583333333333333",
         "0.15833333333333333",
         "-0.45"
        ],
        [
         "12",
         "0.5",
         "0.8166666666666667",
         "0.15000000000000002",
         "0.8166666666666667",
         "0.31666666666666665",
         "-0.35"
        ],
        [
         "13",
         "0.5",
         "0.975",
         "0.25",
         "0.975",
         "0.475",
         "-0.25"
        ],
        [
         "14",
         "0.5",
         "0.025000000000000022",
         "0.33299999999999996",
         "0.025000000000000022",
         "-0.475",
         "-0.167"
        ],
        [
         "15",
         "0.5",
         "0.18333333333333335",
         "0.417",
         "0.18333333333333335",
         "-0.31666666666666665",
         "-0.083"
        ],
        [
         "16",
         "0.5",
         "0.3416666666666667",
         "0.5",
         "0.3416666666666667",
         "-0.15833333333333333",
         "0.0"
        ],
        [
         "17",
         "0.5",
         "0.5",
         "0.583",
         "0.5",
         "0.0",
         "0.083"
        ],
        [
         "18",
         "0.5",
         "0.6583333333333333",
         "0.667",
         "0.6583333333333333",
         "0.15833333333333333",
         "0.167"
        ],
        [
         "19",
         "0.5",
         "0.8166666666666667",
         "0.75",
         "0.8166666666666667",
         "0.31666666666666665",
         "0.25"
        ],
        [
         "20",
         "0.5",
         "0.975",
         "0.85",
         "0.975",
         "0.475",
         "0.35"
        ],
        [
         "21",
         "0.5",
         "0.025000000000000022",
         "0.95",
         "0.025000000000000022",
         "-0.475",
         "0.45"
        ],
        [
         "22",
         "0.5",
         "0.18333333333333335",
         "0.04999999999999999",
         "0.18333333333333335",
         "-0.31666666666666665",
         "-0.45"
        ],
        [
         "23",
         "0.5",
         "0.3416666666666667",
         "0.15000000000000002",
         "0.3416666666666667",
         "-0.15833333333333333",
         "-0.35"
        ],
        [
         "24",
         "0.5",
         "0.5",
         "0.25",
         "0.5",
         "0.0",
         "-0.25"
        ],
        [
         "25",
         "0.5",
         "0.6583333333333333",
         "0.33299999999999996",
         "0.6583333333333333",
         "0.15833333333333333",
         "-0.167"
        ],
        [
         "26",
         "0.5",
         "0.8166666666666667",
         "0.417",
         "0.8166666666666667",
         "0.31666666666666665",
         "-0.083"
        ],
        [
         "27",
         "0.5",
         "0.975",
         "0.5",
         "0.975",
         "0.475",
         "0.0"
        ],
        [
         "28",
         "0.5",
         "0.025000000000000022",
         "0.583",
         "0.025000000000000022",
         "-0.475",
         "0.083"
        ],
        [
         "29",
         "0.5",
         "0.18333333333333335",
         "0.667",
         "0.18333333333333335",
         "-0.31666666666666665",
         "0.167"
        ],
        [
         "30",
         "0.5",
         "0.3416666666666667",
         "0.75",
         "0.3416666666666667",
         "-0.15833333333333333",
         "0.25"
        ],
        [
         "31",
         "0.5",
         "0.5",
         "0.85",
         "0.5",
         "0.0",
         "0.35"
        ],
        [
         "32",
         "0.5",
         "0.6583333333333333",
         "0.95",
         "0.6583333333333333",
         "0.15833333333333333",
         "0.45"
        ],
        [
         "33",
         "0.5",
         "0.8166666666666667",
         "0.04999999999999999",
         "0.8166666666666667",
         "0.31666666666666665",
         "-0.45"
        ],
        [
         "34",
         "0.5",
         "0.975",
         "0.15000000000000002",
         "0.975",
         "0.475",
         "-0.35"
        ],
        [
         "35",
         "0.5",
         "0.025000000000000022",
         "0.25",
         "0.025000000000000022",
         "-0.475",
         "-0.25"
        ],
        [
         "36",
         "0.5",
         "0.18333333333333335",
         "0.33299999999999996",
         "0.18333333333333335",
         "-0.31666666666666665",
         "-0.167"
        ],
        [
         "37",
         "0.5",
         "0.3416666666666667",
         "0.417",
         "0.3416666666666667",
         "-0.15833333333333333",
         "-0.083"
        ],
        [
         "38",
         "0.5",
         "0.5",
         "0.5",
         "0.5",
         "0.0",
         "0.0"
        ],
        [
         "39",
         "0.5",
         "0.6583333333333333",
         "0.583",
         "0.6583333333333333",
         "0.15833333333333333",
         "0.083"
        ],
        [
         "40",
         "0.5",
         "0.8166666666666667",
         "0.667",
         "0.8166666666666667",
         "0.31666666666666665",
         "0.167"
        ],
        [
         "41",
         "0.5",
         "0.975",
         "0.75",
         "0.975",
         "0.475",
         "0.25"
        ],
        [
         "42",
         "0.5",
         "0.025000000000000022",
         "0.85",
         "0.025000000000000022",
         "-0.475",
         "0.35"
        ],
        [
         "43",
         "0.5",
         "0.18333333333333335",
         "0.95",
         "0.18333333333333335",
         "-0.31666666666666665",
         "0.45"
        ],
        [
         "44",
         "0.5",
         "0.3416666666666667",
         "0.04999999999999999",
         "0.3416666666666667",
         "-0.15833333333333333",
         "-0.45"
        ],
        [
         "45",
         "0.5",
         "0.5",
         "0.15000000000000002",
         "0.5",
         "0.0",
         "-0.35"
        ],
        [
         "46",
         "0.5",
         "0.6583333333333333",
         "0.25",
         "0.6583333333333333",
         "0.15833333333333333",
         "-0.25"
        ],
        [
         "47",
         "0.5",
         "0.8166666666666667",
         "0.33299999999999996",
         "0.8166666666666667",
         "0.31666666666666665",
         "-0.167"
        ],
        [
         "48",
         "0.5",
         "0.975",
         "0.417",
         "0.975",
         "0.475",
         "-0.083"
        ],
        [
         "49",
         "0.5",
         "0.025000000000000022",
         "0.5",
         "0.025000000000000022",
         "-0.475",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 9988
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S_a_s</th>\n",
       "      <th>S_a_t</th>\n",
       "      <th>S_v_s</th>\n",
       "      <th>S_v_t</th>\n",
       "      <th>delta</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.475000</td>\n",
       "      <td>-0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>-0.316667</td>\n",
       "      <td>-0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>-0.158333</td>\n",
       "      <td>-0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>-0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>-0.316667</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>-0.158333</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9988 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      S_a_s     S_a_t  S_v_s     S_v_t     delta      c\n",
       "0       0.5  0.025000  0.050  0.025000 -0.475000 -0.450\n",
       "1       0.5  0.183333  0.150  0.183333 -0.316667 -0.350\n",
       "2       0.5  0.341667  0.250  0.341667 -0.158333 -0.250\n",
       "3       0.5  0.500000  0.333  0.500000  0.000000 -0.167\n",
       "4       0.5  0.658333  0.417  0.658333  0.158333 -0.083\n",
       "...     ...       ...    ...       ...       ...    ...\n",
       "9983    0.5  0.183333  0.583  0.183333 -0.316667  0.083\n",
       "9984    0.5  0.341667  0.667  0.341667 -0.158333  0.167\n",
       "9985    0.5  0.500000  0.750  0.500000  0.000000  0.250\n",
       "9986    0.5  0.658333  0.850  0.658333  0.158333  0.350\n",
       "9987    0.5  0.816667  0.950  0.816667  0.316667  0.450\n",
       "\n",
       "[9988 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf04c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data summary:\n",
      "S_a_t min: 0.025, max: 0.975\n",
      "S_v_t min: 0.025, max: 0.975\n",
      "S_v_s min: 0.050, max: 0.950\n",
      "\n",
      "Negative/zero durations:\n",
      "S_a_t <= 0: 0 cases\n",
      "S_v_t <= 0: 0 cases\n",
      "S_v_s <= 0: 0 cases\n"
     ]
    }
   ],
   "source": [
    "# Check for potential issues with negative durations\n",
    "print(\"Data summary:\")\n",
    "print(f\"S_a_t min: {simData['S_a_t'].min():.3f}, max: {simData['S_a_t'].max():.3f}\")\n",
    "print(f\"S_v_t min: {simData['S_v_t'].min():.3f}, max: {simData['S_v_t'].max():.3f}\")\n",
    "print(f\"S_v_s min: {simData['S_v_s'].min():.3f}, max: {simData['S_v_s'].max():.3f}\")\n",
    "\n",
    "# Check if any values are negative or zero\n",
    "negative_Sa_t = simData[simData['S_a_t'] <= 0]\n",
    "negative_Sv_t = simData[simData['S_v_t'] <= 0] \n",
    "negative_Sv_s = simData[simData['S_v_s'] <= 0]\n",
    "\n",
    "print(f\"\\nNegative/zero durations:\")\n",
    "print(f\"S_a_t <= 0: {len(negative_Sa_t)} cases\")\n",
    "print(f\"S_v_t <= 0: {len(negative_Sv_t)} cases\") \n",
    "print(f\"S_v_s <= 0: {len(negative_Sv_s)} cases\")\n",
    "\n",
    "if len(negative_Sv_s) > 0:\n",
    "    print(f\"Example negative S_v_s: {negative_Sv_s[['S_v_s', 'c']].head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FUSION MODEL IMPLEMENTATION ---\n",
    "def fusion_estimate(m_a, m_v, sigma_a, sigma_v):\n",
    "    \"\"\"Bayesian optimal integration of auditory and visual measurements.\"\"\"\n",
    "    # Calculate weights based on reliabilities (inverse variances)\n",
    "    w_a = 1 / sigma_a**2\n",
    "    w_v = 1 / sigma_v**2\n",
    "    # Compute the fused estimate\n",
    "    fused_estimate = (w_a * m_a + w_v * m_v) / (w_a + w_v)\n",
    "    return fused_estimate\n",
    "\n",
    "# --- CAUSAL INFERENCE MODEL IMPLEMENTATION ---\n",
    "def p_single(m,sigma,t_min,t_max):\n",
    "    \"\"\"p(m | C=2) and Gaussian measurement noise N(m; y, sigma^2).\"\"\"\n",
    "    hi_cdf= norm.cdf((t_max - m) /sigma)\n",
    "    lo_cdf=norm.cdf((t_min-m)/sigma)\n",
    "    return (hi_cdf-lo_cdf)/(t_max-t_min)\n",
    "\n",
    "# Causal inference model for duration estimation\n",
    "def L_C1(m_a,m_v,sigma_a,sigma_v,t_min,t_max):\n",
    "    sigma_c_sq = (sigma_a**2 * sigma_v**2) / (sigma_a**2 + sigma_v**2)\n",
    "    sigma_c = np.sqrt(sigma_c_sq)\n",
    "    mu_c = (m_a / sigma_a**2 + m_v / sigma_v**2) / (1 / sigma_a**2 + 1 / sigma_v**2)\n",
    "\n",
    "    hi_cdf = norm.cdf((t_max-mu_c)/sigma_c)\n",
    "    lo_cdf = norm.cdf((t_min-mu_c)/sigma_c)\n",
    "    \n",
    "    expo = np.exp(-(m_a-m_v)**2/(2*(sigma_a**2+sigma_v**2)))\n",
    "    \n",
    "    prior = 1/(t_max-t_min)\n",
    "    return prior * sigma_c/np.sqrt(sigma_a**2 * sigma_v**2) * (hi_cdf-lo_cdf) * expo\n",
    "\n",
    "def L_C2(m_a,m_v,sigma_a,sigma_v,t_min,t_max):\n",
    "    \"\"\" Likelihood of separate sources: product of two marginal likelihoods \n",
    "        two integral over two hidden duration y_a y_v\"\"\"\n",
    "    return p_single(m_a,sigma_a,t_min,t_max) * p_single(m_v,sigma_v,t_min,t_max)\n",
    "\n",
    "def posterior_C1(m_a,m_v,sigma_a,sigma_v,p_c,t_min,t_max):\n",
    "    \"\"\" Posterior probability of common cause P(C=1 | m_a,m_v) \"\"\"\n",
    "    # Likelihoods under each causal structure\n",
    "    L1 = L_C1(m_a,m_v,sigma_a,sigma_v,t_min,t_max)\n",
    "    L2 = L_C2(m_a,m_v,sigma_a,sigma_v,t_min,t_max)\n",
    "    # Unnormalized posteriors\n",
    "    post_C1_unnorm = L1 * p_c\n",
    "    post_C2_unnorm = L2 * (1 - p_c)\n",
    "    # Normalization constant\n",
    "    norm_const = post_C1_unnorm + post_C2_unnorm\n",
    "    \n",
    "    # Handle numerical stability\n",
    "    if np.isscalar(norm_const):\n",
    "        if norm_const == 0:\n",
    "            return 0.5\n",
    "    else:\n",
    "        norm_const = np.where(norm_const == 0, 1e-10, norm_const)\n",
    "    \n",
    "    # Posterior probabilities\n",
    "    post_C1 = post_C1_unnorm / norm_const\n",
    "    return post_C1\n",
    "\n",
    "def causal_inference_estimate(m_a, m_v, sigma_a, sigma_v, p_c, t_min, t_max, model):\n",
    "    \"\"\"Causal inference duration estimate (stays in current space - log or linear)\"\"\"\n",
    "    # Posterior probability of common cause\n",
    "    p_C1 = posterior_C1(m_a, m_v, sigma_a, sigma_v, p_c, t_min, t_max)\n",
    "    \n",
    "    # Estimate under common cause (fused estimate)\n",
    "    est_C1 = fusion_estimate(m_a, m_v, sigma_a, sigma_v)\n",
    "    # Estimate under separate causes (auditory estimate)\n",
    "    est_C2 = m_a\n",
    "    \n",
    "    # Final estimate as a weighted average\n",
    "    final_estimate = p_C1 * est_C1 + (1 - p_C1) * est_C2\n",
    "    \n",
    "    if model == \"log-space\":\n",
    "        final_estimate = p_C1 * est_C1 + (1 - p_C1) * est_C2\n",
    "        final_estimate = np.exp(final_estimate)\n",
    "    return final_estimate\n",
    "\n",
    "def forced_fusion_estimate(m_a, m_v, sigma_a, sigma_v, model):\n",
    "    \"\"\"Forced fusion model - always fuses, no causal inference\"\"\"\n",
    "    fused = fusion_estimate(m_a, m_v, sigma_a, sigma_v)\n",
    "    \n",
    "    if model == \"log-space\":\n",
    "        # Convert back to linear space\n",
    "        return np.exp(fused)\n",
    "    else:\n",
    "        return fused\n",
    "\n",
    "def estimate_duration(m_a,m_v,sigma_a,sigma_v,p_c,t_min,t_max,lambda_=0.1, model=\"linear-space\"):\n",
    "    \"\"\" Final duration estimate as a weighted average of estimates under each causal structure \"\"\"\n",
    "    \n",
    "    if model == \"log-space\":\n",
    "        # For log-space model: measurements are in log space, causal inference in log space\n",
    "        # t_min and t_max should also be in log space\n",
    "        log_t_min = np.log(t_min)\n",
    "        log_t_max = np.log(t_max)        \n",
    "        # Do causal inference in log space\n",
    "        final_estimate = causal_inference_estimate(m_a, m_v, sigma_a, sigma_v, p_c, log_t_min, log_t_max, model=model)\n",
    "    else:  # linear-space\n",
    "        # For linear-space model: everything in linear space\n",
    "        final_estimate = causal_inference_estimate(m_a, m_v, sigma_a, sigma_v, p_c, t_min, t_max, model=model)\n",
    "    \n",
    "    return final_estimate\n",
    "\n",
    "def estimate_probability_matching(m_a, m_v, sigma_a, sigma_v, p_c, t_min, t_max, model=\"linear-space\"):\n",
    "    \"\"\" Probability matching model - sample from the posterior distribution \"\"\"\n",
    "    if model == \"log-space\":\n",
    "        t_min = np.log(t_min)\n",
    "        t_max = np.log(t_max)\n",
    "    # Calculate posterior probability of common cause\n",
    "    post_C1 = posterior_C1(m_a, m_v, sigma_a, sigma_v, p_c, t_min, t_max)\n",
    "    est_fused = fusion_estimate(m_a, m_v, sigma_a, sigma_v)\n",
    "    est_separate = m_a\n",
    "    # or have it as probability from uniform distribution\n",
    "    b= np.random.uniform(0,1,size=post_C1.shape) < post_C1\n",
    "    \n",
    "    # Probability matching estimate based on sampled causal structure\n",
    "    final_estimate = b * est_fused + (1 - b) * est_separate\n",
    "    \n",
    "    if model == \"log-space\":\n",
    "        final_estimate = np.exp(final_estimate)\n",
    "    \n",
    "    return final_estimate\n",
    "\n",
    "def estimate_selection(m_a, m_v, sigma_a, sigma_v, p_c, t_min, t_max, model=\"linear-space\"):\n",
    "    \"\"\" Selection model - choose the estimate from the most probable causal structure \"\"\"\n",
    "    if model == \"log-space\":\n",
    "        t_min = np.log(t_min)\n",
    "        t_max = np.log(t_max)\n",
    "    # Calculate posterior probability of common cause\n",
    "    post_C1 = posterior_C1(m_a, m_v, sigma_a, sigma_v, p_c, t_min, t_max)\n",
    "    est_fused = fusion_estimate(m_a, m_v, sigma_a, sigma_v)\n",
    "    est_separate = m_a\n",
    "    \n",
    "    # Determine which causal structure is more probable\n",
    "    # Handle both scalar and array cases\n",
    "    if np.isscalar(post_C1):\n",
    "        b = post_C1 > 0.5\n",
    "    else:\n",
    "        b = post_C1 > 0.5\n",
    "    \n",
    "    # Select estimate based on most probable causal structure\n",
    "    final_estimate = b * est_fused + (1 - b) * est_separate\n",
    "    \n",
    "    if model == \"log-space\":\n",
    "        final_estimate = np.exp(final_estimate)\n",
    "    \n",
    "    return final_estimate\n",
    "\n",
    "def estimate_switch(m_a, m_v, sigma_a, sigma_v, p_c, t_min, t_max, model=\"linear-space\"):\n",
    "    \"\"\" Switching model - switch between auditory and visual estimates based on reliability \"\"\"\n",
    "    if model == \"log-space\": # we might not need this but just for consistency\n",
    "        t_min = np.log(t_min)\n",
    "        t_max = np.log(t_max)\n",
    "    \n",
    "    # Determine which modality is more reliable (lower noise = higher reliability)\n",
    "    # Probability of using auditory = visual noise / (auditory noise + visual noise)\n",
    "    p_switch = sigma_a**2 / (sigma_a**2 + sigma_v**2)\n",
    "    \n",
    "    # Handle array shape for random sampling\n",
    "    if np.isscalar(m_a):\n",
    "        shape = 1\n",
    "    else:\n",
    "        shape = m_a.shape\n",
    "    \n",
    "    # Randomly decide which modality to use based on reliability\n",
    "    use_visual = np.random.uniform(0, 1, size=shape) < p_switch\n",
    "    \n",
    "    # Select estimate based on chosen modality\n",
    "    final_estimate = (1-use_visual) * m_a + use_visual * m_v\n",
    "\n",
    "    if model == \"log-space\":\n",
    "        final_estimate = np.exp(final_estimate)\n",
    "    return final_estimate\n",
    "\n",
    "def estimate_switch_with_conflict(m_a, m_v, sigma_a, sigma_v, p_c, t_min, t_max, conflict, model=\"linear-space\"):\n",
    "    \"\"\" Switching model with conflict sensitivity - bias towards auditory with higher conflict \"\"\"\n",
    "    if model == \"log-space\": # we might not need this but just for consistency\n",
    "        t_min = np.log(t_min)\n",
    "        t_max = np.log(t_max)\n",
    "    \n",
    "    # Determine which modality is more reliable (lower noise = higher reliability)\n",
    "    base_p_switch = sigma_v**2 / (sigma_a**2 + sigma_v**2)\n",
    "    \n",
    "    posterior_C1= posterior_C1(m_a, m_v, sigma_a, sigma_v, p_c, t_min, t_max)\n",
    "    \n",
    "    p_sub = base_p_switch * (1 - posterior_C1)\n",
    "    # Handle array shape for random sampling\n",
    "    if np.isscalar(m_a):\n",
    "        shape = 1\n",
    "    else:\n",
    "        shape = m_a.shape\n",
    "    # Randomly decide which modality to use based on reliability and conflict\n",
    "    use_visual = np.random.uniform(0, 1, size=shape) < p_sub    \n",
    "    # Select estimate based on chosen modality\n",
    "    final_estimate = (1-use_visual) * m_a + use_visual * m_v    \n",
    "    if model == \"log-space\":\n",
    "        final_estimate = np.exp(final_estimate)\n",
    "    return final_estimate\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "# Calculate probabilities of choosing test longer than standard for each condition\n",
    "def prob_test_longer_condition(S_a_s, S_a_t, S_v_s, S_v_t, sigma_a, sigma_v, p_c, t_min, t_max, lambda_=0.1, measurement=\"linear-space\",model=\"CausalInference\", nSimul=1000):\n",
    "    \"\"\" Calculate the probability of choosing the test duration as longer than the standard duration for a specific condition. \"\"\"\n",
    "    \n",
    "    # Check for invalid durations (≤ 0) when using log-space\n",
    "    if measurement == \"log-space\":\n",
    "        min_duration = 1e-6  # Very small positive number\n",
    "        S_a_s = max(S_a_s, min_duration)\n",
    "        S_a_t = max(S_a_t, min_duration)\n",
    "        S_v_s = max(S_v_s, min_duration)\n",
    "        S_v_t = max(S_v_t, min_duration)\n",
    "    \n",
    "    # Generate measurements with noise\n",
    "    if measurement == \"log-space\":\n",
    "        # Measurements are Gaussian in log space (like your main implementation)\n",
    "        m_a_s = np.random.normal(np.log(S_a_s), scale=sigma_a, size=nSimul)\n",
    "        m_a_t = np.random.normal(np.log(S_a_t), scale=sigma_a, size=nSimul)\n",
    "        m_v_s = np.random.normal(np.log(S_v_s), scale=sigma_v, size=nSimul)\n",
    "        m_v_t = np.random.normal(np.log(S_v_t), scale=sigma_v, size=nSimul)\n",
    "    elif measurement == \"linear-space\":\n",
    "        m_a_s = np.random.normal(S_a_s, scale=sigma_a, size=nSimul)\n",
    "        m_a_t = np.random.normal(S_a_t, scale=sigma_a, size=nSimul)\n",
    "        m_v_s = np.random.normal(S_v_s, scale=sigma_v, size=nSimul)\n",
    "        m_v_t = np.random.normal(S_v_t, scale=sigma_v, size=nSimul)\n",
    "\n",
    "\n",
    "    \n",
    "    if model==\"ForcedFusion\":\n",
    "        # Forced fusion: always integrate, no causal inference\n",
    "        est_standard = forced_fusion_estimate(m_a_s, m_v_s, sigma_a, sigma_v, measurement)\n",
    "        est_test = forced_fusion_estimate(m_a_t, m_v_t, sigma_a, sigma_v, measurement)\n",
    "    elif model==\"CausalInference\":\n",
    "        # Causal inference model\n",
    "        est_standard = estimate_duration(m_a_s, m_v_s, sigma_a, sigma_v, p_c, t_min, t_max, lambda_, measurement)\n",
    "        est_test = estimate_duration(m_a_t, m_v_t, sigma_a, sigma_v, p_c, t_min, t_max, lambda_, measurement)\n",
    "    elif model==\"ProbabilityMatching\":\n",
    "        # Probability matching model\n",
    "        est_standard = estimate_probability_matching(m_a_s, m_v_s, sigma_a, sigma_v, p_c, t_min, t_max, measurement)\n",
    "        est_test = estimate_probability_matching(m_a_t, m_v_t, sigma_a, sigma_v, p_c, t_min, t_max, measurement)\n",
    "    elif model==\"Selection\":\n",
    "        # Selection model\n",
    "        est_standard = estimate_selection(m_a_s, m_v_s, sigma_a, sigma_v, p_c, t_min, t_max, measurement)\n",
    "        est_test = estimate_selection(m_a_t, m_v_t, sigma_a, sigma_v, p_c, t_min, t_max, measurement)\n",
    "    elif model==\"Switching\":\n",
    "        # Switching model\n",
    "        est_standard = estimate_switch(m_a_s, m_v_s, sigma_a, sigma_v, p_c, t_min, t_max, measurement)\n",
    "        est_test = estimate_switch(m_a_t, m_v_t, sigma_a, sigma_v, p_c, t_min, t_max, measurement)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Invalid model specified. Choose 'ForcedFusion', 'CausalInference', 'ProbabilityMatching', 'Selection', or 'Switching'.\")\n",
    "    # Calculate probability\n",
    "    p_base = np.mean(est_test > est_standard)\n",
    "    p_final = (1 - lambda_) * p_base + lambda_ * 0.5\n",
    "    return p_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02d61f",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0069e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated simulation function that generates psychometric curves for all three models\n",
    "def simulate_duration_estimation(sigma_a=0.05, sigma_v=0.1, p_c=0.5, lambda_=0.1, measurement=\"linear-space\", nSimul=1000, t_min=0.01, t_max=3.0, selected_model=\"CausalInference\"):\n",
    "    \"\"\"\n",
    "    Simulate duration estimation and generate psychometric curves for all three models simultaneously.\n",
    "    \"\"\"\n",
    "    # Get unique conditions\n",
    "    unique_deltas = np.sort(simData['delta'].unique())\n",
    "    unique_conflicts = np.sort(simData['c'].unique())\n",
    "    \n",
    "    # Initialize results storage for all three models\n",
    "    models = ['CausalInference', 'ForcedFusion', 'ProbabilityMatching', 'Selection', 'Switching']\n",
    "    all_results = {model: [] for model in models}\n",
    "    \n",
    "    # For each conflict level\n",
    "    for conflict in unique_conflicts:\n",
    "        # For each delta (test duration difference)\n",
    "        for delta in unique_deltas:\n",
    "            # Get the stimulus durations for this condition\n",
    "            S_a_s = 0.5  # Standard auditory duration\n",
    "            S_a_t = S_a_s + delta  # Test auditory duration\n",
    "            S_v_s = S_a_s + conflict  # Standard visual duration (with conflict)\n",
    "            S_v_t = S_a_t  # Test visual duration (same as auditory test)\n",
    "            \n",
    "            # Skip conditions with non-positive durations for log-space\n",
    "            if measurement == \"log-space\" and (S_a_t <= 0 or S_v_t <= 0 or S_v_s <= 0):\n",
    "                continue\n",
    "            \n",
    "            # Calculate probability for each model\n",
    "            for model in models:\n",
    "                p_longer = prob_test_longer_condition(\n",
    "                    S_a_s, S_a_t, S_v_s, S_v_t, \n",
    "                    sigma_a, sigma_v, p_c, t_min, t_max, lambda_, measurement, model, nSimul\n",
    "                )\n",
    "                \n",
    "                all_results[model].append({\n",
    "                    'delta': delta,\n",
    "                    'delta_ms': delta * 1000,\n",
    "                    'conflict': conflict,\n",
    "                    'conflict_ms': conflict * 1000,\n",
    "                    'p_test_longer': p_longer,\n",
    "                    'S_a_s': S_a_s,\n",
    "                    'S_a_t': S_a_t,\n",
    "                    'S_v_s': S_v_s,\n",
    "                    'S_v_t': S_v_t,\n",
    "                    'model': model\n",
    "                })\n",
    "    \n",
    "    # Convert to DataFrames for easier plotting\n",
    "    results_dfs = {model: pd.DataFrame(all_results[model]) for model in models}\n",
    "    \n",
    "    if len(results_dfs['CausalInference']) == 0:\n",
    "        return results_dfs\n",
    "    \n",
    "    # Plotting - Only 2 plots\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    \n",
    "    # Plot 1: Psychometric curves for selected model only\n",
    "    plt.subplot(1, 2, 1)\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(unique_conflicts)))\n",
    "    \n",
    "    # Plot only the selected model\n",
    "    for i, conflict in enumerate(unique_conflicts):\n",
    "        conflict_data = results_dfs[selected_model][results_dfs[selected_model]['conflict'] == conflict]\n",
    "        if len(conflict_data) > 0:\n",
    "            plt.plot(conflict_data['delta_ms'], conflict_data['p_test_longer'], \n",
    "                    'o-', color=colors[i], \n",
    "                    label=f'c: {conflict*1000:.0f}ms',\n",
    "                    alpha=0.8, linewidth=2)\n",
    "    \n",
    "    plt.title(f'Psychometric Curves: {selected_model}')\n",
    "    plt.xlabel('Test Duration Difference from Standard (ms)')\n",
    "    plt.ylabel('P(Choosing Test as Longer)')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.axhline(0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "    plt.axvline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    \n",
    "    # Plot 2: PSE comparison for all models\n",
    "    plt.subplot(1, 2, 2)\n",
    "    pse_by_conflict = {model: [] for model in models}\n",
    "    \n",
    "    # Calculate PSE for each model\n",
    "    for model in models:\n",
    "        for conflict in unique_conflicts:\n",
    "            conflict_data = results_dfs[model][results_dfs[model]['conflict'] == conflict].sort_values('delta_ms')\n",
    "            if len(conflict_data) > 1:\n",
    "                try:\n",
    "                    p_values = conflict_data['p_test_longer'].values\n",
    "                    delta_values = conflict_data['delta_ms'].values\n",
    "                    \n",
    "                    if p_values.min() <= 0.5 <= p_values.max():\n",
    "                        pse = np.interp(0.5, p_values, delta_values)\n",
    "                    else:\n",
    "                        closest_idx = np.argmin(np.abs(p_values - 0.5))\n",
    "                        pse = delta_values[closest_idx]\n",
    "                    \n",
    "                    pse_by_conflict[model].append({\n",
    "                        'conflict_ms': conflict*1000, \n",
    "                        'pse_ms': pse,\n",
    "                        'conflict': conflict\n",
    "                    })\n",
    "                except:\n",
    "                    pse_by_conflict[model].append({\n",
    "                        'conflict_ms': conflict*1000, \n",
    "                        'pse_ms': 0,\n",
    "                        'conflict': conflict\n",
    "                    })\n",
    "    \n",
    "    # Plot PSE curves for all models - Updated with colors for all 5 models\n",
    "    colors_models = {\n",
    "        'CausalInference': 'red', \n",
    "        'ForcedFusion': 'blue', \n",
    "        'ProbabilityMatching': 'green',\n",
    "        'Selection': 'orange',\n",
    "        'Switching': 'purple'\n",
    "    }\n",
    "    markers = {\n",
    "        'CausalInference': 'o', \n",
    "        'ForcedFusion': 's', \n",
    "        'ProbabilityMatching': '^',\n",
    "        'Selection': 'D',\n",
    "        'Switching': 'v'\n",
    "    }\n",
    "    line_styles = {\n",
    "        'CausalInference': '-', \n",
    "        'ForcedFusion': '--', \n",
    "        'ProbabilityMatching': ':',\n",
    "        'Selection': '-.',\n",
    "        'Switching': '-'\n",
    "    }\n",
    "    \n",
    "    for model in models:\n",
    "        if pse_by_conflict[model]:\n",
    "            pse_df = pd.DataFrame(pse_by_conflict[model])\n",
    "            plt.plot(pse_df['conflict_ms'], pse_df['pse_ms'], \n",
    "                    markers[model] + line_styles[model], \n",
    "                    color=colors_models[model], linewidth=2, markersize=8, \n",
    "                    label=model, alpha=0.8)\n",
    "    \n",
    "    plt.title('PSE vs Conflict: All Models Comparison')\n",
    "    plt.xlabel('Conflict Level (ms)')\n",
    "    plt.ylabel('PSE (ms from standard)')\n",
    "    plt.ylim(-500, 500)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    # Vertical cut lines at ±250 ms\n",
    "    ax = plt.gca()\n",
    "    ax.axvline(+250, color='black', linestyle='-', alpha=0.3)\n",
    "    ax.axvline(-250, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "    # Shade regions beyond the ±250 ms bounds\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    if xmax > 250:\n",
    "        ax.axvspan(max(250, xmin), xmax, color='lightgray', alpha=0.2, linewidth=0)\n",
    "    if xmin < -250:\n",
    "        ax.axvspan(xmin, min(-250, xmax), color='lightgray', alpha=0.2, linewidth=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a83099d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a063e7bce2049d5a42aa0605545a36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='σₐ (auditory):', max=1.0, min=0.01, step=0.01), Floa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive widget for parameter exploration\n",
    "def interactive_simulation_with_model_selection(sigma_a=0.05, sigma_v=0.1, p_c=0.5, lambda_=0.1, model_space=\"linear-space\", n_simulations=500, t_min=0.01, t_max=3.0, selected_model=\"CausalInference\"):\n",
    "    \"\"\"Interactive version of the simulation with parameter controls and model selection\"\"\"\n",
    "    results = simulate_duration_estimation(\n",
    "        sigma_a=sigma_a, \n",
    "        sigma_v=sigma_v, \n",
    "        p_c=p_c, \n",
    "        lambda_=lambda_, \n",
    "        measurement=model_space, \n",
    "        nSimul=n_simulations,\n",
    "        t_min=t_min,\n",
    "        t_max=t_max,\n",
    "        selected_model=selected_model\n",
    "    )\n",
    "    return results\n",
    "\n",
    "# Create interactive widget\n",
    "from ipywidgets import interact, FloatSlider, Dropdown, IntSlider\n",
    "\n",
    "interact(\n",
    "    interactive_simulation_with_model_selection,\n",
    "    sigma_a=FloatSlider(value=0.5, min=0.01, max=1, step=0.01, description='σₐ (auditory):'),\n",
    "    sigma_v=FloatSlider(value=0.3, min=0.01, max=0.8, step=0.01, description='σᵥ (visual):'),\n",
    "    p_c=FloatSlider(value=0.5, min=0.0, max=1.0, step=0.01, description='p_c (common cause):'),\n",
    "    lambda_=FloatSlider(value=0.1, min=0.0, max=0.5, step=0.01, description='λ (lapse rate):'),\n",
    "    model_space=Dropdown(options=['linear-space', 'log-space'], value='log-space', description='Measurement space:'),\n",
    "    n_simulations=IntSlider(value=1000, min=100, max=10000, step=100, description='N simulations:'),\n",
    "    t_min=FloatSlider(value=0.01, min=0.001, max=0.5, step=0.001, description='t_min (s):'),\n",
    "    t_max=FloatSlider(value=3.0, min=0.5, max=5.0, step=0.01, description='t_max (s):'),\n",
    "    selected_model=Dropdown(options=['CausalInference', 'ForcedFusion', 'ProbabilityMatching','Switching','Selection'], value='CausalInference', description='Model for Plot 1:')\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce1d632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mathmod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
